{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Unsupervised Learning \n",
    "We will now focus on deep learrning on large, unlabeled datasets: *deep unsupervised learning*. \n",
    "\n",
    "This is a very new field, full of potential but with fewer commericial sucesses as of date. \n",
    "\n",
    "# Boltzmann Machines\n",
    "Now we will move into *generative unsupervised models* which involve learning a probability distribution from an original dataset and using it to make inferences about never before seen data. \n",
    "\n",
    "We have mainly looked at *discriminative models* that learn to seperate observaations based on waht the algorithms learn from the data. \n",
    "\n",
    "These discriminative models do not learn the probability distribution from the data. Discrimiative models such as: logistic regression, decision trees, clustering methods. \n",
    "\n",
    "Boltzmann machines (unrestricted) consist of a neural network with an input layer and one or several hidden layers. The neurons or units in the neural network make stochastic decisions about whether to turn on or not based on the data fed in during training and the cost function they are trying to minimize. \n",
    "\n",
    "It discovers interesting features about the data, which helps model the complex underlying relationships and patterns present in the data. \n",
    "\n",
    "These Boltzmann machines use neural networks with neurons that are connected not only to other neurons in other layers but also to neurons within the same layer. \n",
    "\n",
    "## Restricted Boltzmann Machines\n",
    "RBMs have an input layer (visible layer) and just a single hidden layer, and the connections among neurons are restricted such that neurons are connected only to the neurons in other layers but not to neurons within the same layer. \n",
    "\n",
    "Therefor: No visible-visible connections and no hidden-hidden connections.\n",
    "\n",
    "RBMs stacked on top of each other essentially make up for a what's now known as the field of deep learning. \n",
    "\n",
    "RBMs use a *stochastic* approach to learning the underlying structure of data, whereas autoencoders use a *deterministic* approach. \n",
    "\n",
    "## Recommender Systems\n",
    "We will use RBMs to build a *recommender system*, one of the most successful applications of machine learning to date and widely used in industry to help user preference for movies, music, books, news, search, shopping, digital advertising, and online dating. \n",
    "\n",
    "There are **collaborative filtering** systems and **content-based filtering** recommender systems. \n",
    "\n",
    "*Collaborative filtering* involves building a recommender system from a user's past behavior and those of other users to which the user is similar to. \n",
    "\n",
    "This recommender system can then predict items that the user may have an interest in even though the user has never expressed explicit interest. (netflix uses this system) \n",
    "\n",
    "*Content-based filtering* involves learning the distinct properties of an item to recommend additional items with similar properties. \n",
    "\n",
    "### Collaborative Filtering\n",
    "Content-based filtering is not commonly used because it is a rather difficult task to learn the distinct properties of items - this level of understanding is very challenging for artificial machines to achieve currently. \n",
    "\n",
    "It is much easier to collect and analyze a large amount of information on user's behavior and preferences and make predictions based on this. \n",
    "\n",
    "Collaborative filtering requires no knowledge of the underlying items themselves. Rather, collaborative filtering assumes that users taht agreed in the past will agree in the future and that user preferences remain stable over time. \n",
    "\n",
    "By modeling how similar users are to other users, collaborative filtering can make pretty powerful recommendations. \n",
    "\n",
    "Collaborative filtering does not have to rely on *explicit data* (rating that users provide). Rather, it can work with *implicit data* such as how long or how often a user views or clicks on a particular item. \n",
    "\n",
    "*example: Netflix would ask users to rate movies but now uses implicit user behavior to make inferences about user likes and dislikes*\n",
    "\n",
    "### MoveLens Dataset\n",
    "We will use a movie ratings dataset known as *MovieLens 20M Dataset*. This dataset contains 20,000,263 ratings across 27,278 movies created by 138,493 users of users who rated at least 20 movies each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  189M  100  189M    0     0  16.5M      0  0:00:11  0:00:11 --:--:-- 20.4M\n",
      "Archive:  ./datasets/movielens.zip\n",
      "   creating: ml-20m/\n",
      "  inflating: ml-20m/genome-scores.csv  \n",
      "  inflating: ml-20m/genome-tags.csv  \n",
      "  inflating: ml-20m/links.csv        \n",
      "  inflating: ml-20m/movies.csv       \n",
      "  inflating: ml-20m/ratings.csv      \n",
      "  inflating: ml-20m/README.txt       \n",
      "  inflating: ml-20m/tags.csv         \n"
     ]
    }
   ],
   "source": [
    "# # downloading our data\n",
    "# !curl 'http://files.grouplens.org/datasets/movielens/ml-20m.zip' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:66.0) Gecko/20100101 Firefox/66.0' -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' -H 'Accept-Language: en-US,en;q=0.5' --compressed -H 'Connection: keep-alive' -H 'Cookie: _ga=GA1.2.112438606.1560196437; _gid=GA1.2.1915689949.1560196437; _gat=1' -H 'Upgrade-Insecure-Requests: 1' -o ./datasets/movielens.zip\n",
    "\n",
    "# # unzip\n",
    "# !unzip ./datasets/movielens.zip\n",
    "\n",
    "# # remove zipped file\n",
    "# !rm -rf ./datasets/movielens.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Moving our downloaded data to datasets directory\n",
    "# !mv ml-20m/* datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegomedina-bernal/miniconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing our libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, re, pickle, gzip, datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import log_loss, precision_recall_curve, average_precision_score, roc_curve, auc, roc_auc_score, mean_squared_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Dropout, BatchNormalization, Input, Lambda\n",
    "from keras import regularizers\n",
    "from keras.losses import mse, binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our data\n",
    "file = './datasets/ratings.csv'\n",
    "\n",
    "rating_DF = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000263 entries, 0 to 20000262\n",
      "Data columns (total 4 columns):\n",
      "userId       int64\n",
      "movieId      int64\n",
      "rating       float64\n",
      "timestamp    int64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 610.4 MB\n"
     ]
    }
   ],
   "source": [
    "rating_DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112486027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1        2     3.5  1112486027\n",
       "1       1       29     3.5  1112484676\n",
       "2       1       32     3.5  1112484819\n",
       "3       1       47     3.5  1112484727\n",
       "4       1       50     3.5  1112484580"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting timestamp\n",
    "rating_DF['timestamp'] = rating_DF['timestamp'].apply(lambda x: datetime.datetime.utcfromtimestamp(x).strftime('%Y-%m-%d%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-0223:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-0223:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-0223:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-0223:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-0223:29:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating           timestamp\n",
       "0       1        2     3.5  2005-04-0223:53:47\n",
       "1       1       29     3.5  2005-04-0223:31:16\n",
       "2       1       32     3.5  2005-04-0223:33:39\n",
       "3       1       47     3.5  2005-04-0223:32:07\n",
       "4       1       50     3.5  2005-04-0223:29:40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000263 entries, 0 to 20000262\n",
      "Data columns (total 4 columns):\n",
      "userId       int64\n",
      "movieId      int64\n",
      "rating       float64\n",
      "timestamp    object\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 610.4+ MB\n"
     ]
    }
   ],
   "source": [
    "rating_DF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take a sample of our data to minimize the size. As you can see the original file sie is just about 600MB which can become hard to process unless using tools such as: Dask, etc. \n",
    "\n",
    "We will only focus on the top 1000 most rates movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing index of top 1000 rates movies\n",
    "movie_index = rating_DF.groupby('movieId').count().sort_values(by=\"rating\", ascending=False)[0:1000].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's form the new dataframe\n",
    "rating_DF_2 = rating_DF[rating_DF['movieId'].isin(movie_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId       12840344\n",
       "movieId      12840344\n",
       "rating       12840344\n",
       "timestamp    12840344\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_DF_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12840344 entries, 0 to 20000261\n",
      "Data columns (total 4 columns):\n",
      "userId       int64\n",
      "movieId      int64\n",
      "rating       float64\n",
      "timestamp    object\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 489.8+ MB\n"
     ]
    }
   ],
   "source": [
    "rating_DF_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clearing memory\n",
    "# del rating_DF\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del rating_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now further decrease the size by taking a sample of one thousand users at random and filter the dataset for just these users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing user index\n",
    "user_index = rating_DF_2.groupby('userId').count().sort_values(by='rating', ascending=False).sample(n=1000, random_state=2018).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new DF\n",
    "rating_DF_3 = rating_DF_2[rating_DF_2['userId'].isin(user_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId       90213\n",
       "movieId      90213\n",
       "rating       90213\n",
       "timestamp    90213\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_DF_3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 90213 entries, 4943 to 19955685\n",
      "Data columns (total 4 columns):\n",
      "userId       90213 non-null int64\n",
      "movieId      90213 non-null int64\n",
      "rating       90213 non-null float64\n",
      "timestamp    90213 non-null object\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "rating_DF_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clearing memory\n",
    "del rating_DF_2\n",
    "gc.collect(); gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4943</th>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2013-05-0302:50:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4944</th>\n",
       "      <td>49</td>\n",
       "      <td>163</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2013-05-0302:43:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>49</td>\n",
       "      <td>216</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013-05-0302:45:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>49</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2013-05-0302:50:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>49</td>\n",
       "      <td>333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013-05-0302:44:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  movieId  rating           timestamp\n",
       "4943      49       50     5.0  2013-05-0302:50:26\n",
       "4944      49      163     3.5  2013-05-0302:43:37\n",
       "4945      49      216     3.0  2013-05-0302:45:58\n",
       "4946      49      296     5.0  2013-05-0302:50:13\n",
       "4947      49      333     3.0  2013-05-0302:44:38"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_DF_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90213, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_DF_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindexing movieId and userId to a range of 1 to 1000\n",
    "movies = rating_DF_3['movieId'].unique()\n",
    "movies_DF = pd.DataFrame(data=movies, columns=['original_movie_id'])\n",
    "movies_DF['new_movie_id'] = movies_DF.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users\n",
    "users = rating_DF_3['userId'].unique()\n",
    "user_DF = pd.DataFrame(data=users, columns=['original_user_id'])\n",
    "user_DF['new_user_id'] = user_DF.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_DF_3 = rating_DF_3.merge(movies_DF, left_on='movieId', right_on='original_movie_id')\n",
    "rating_DF_3.drop(labels='original_movie_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_DF_3 = rating_DF_3.merge(user_DF, left_on='userId', right_on='original_user_id')\n",
    "rating_DF_3.drop(labels='original_user_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>new_movie_id</th>\n",
       "      <th>new_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2013-05-0302:50:26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>163</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2013-05-0302:43:37</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>216</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013-05-0302:45:58</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2013-05-0302:50:13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013-05-0302:44:38</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating           timestamp  new_movie_id  new_user_id\n",
       "0      49       50     5.0  2013-05-0302:50:26             1            1\n",
       "1      49      163     3.5  2013-05-0302:43:37             2            1\n",
       "2      49      216     3.0  2013-05-0302:45:58             3            1\n",
       "3      49      296     5.0  2013-05-0302:50:13             4            1\n",
       "4      49      333     3.0  2013-05-0302:44:38             5            1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_DF_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculating \n",
    "n_users = rating_DF_3['userId'].nunique()\n",
    "n_movies = rating_DF_3['movieId'].nunique()\n",
    "n_ratings = len(rating_DF_3)\n",
    "avg_ratings_per_user = n_ratings / n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating test train split\n",
    "X_train, X_test = train_test_split(rating_DF_3, test_size=0.10, shuffle=True, random_state=2018)\n",
    "\n",
    "# Creating new split on X_train\n",
    "X_validation, X_test = train_test_split(X_test, test_size=0.50, shuffle=True, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81191\n",
      "4511\n",
      "4511\n"
     ]
    }
   ],
   "source": [
    "# sizes\n",
    "print(len(X_train))\n",
    "print(len(X_validation))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>new_movie_id</th>\n",
       "      <th>new_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77796</th>\n",
       "      <td>118358</td>\n",
       "      <td>2918</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-03-1713:11:50</td>\n",
       "      <td>725</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20109</th>\n",
       "      <td>48345</td>\n",
       "      <td>1907</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2003-01-2605:32:21</td>\n",
       "      <td>345</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61046</th>\n",
       "      <td>25880</td>\n",
       "      <td>74458</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2010-11-2109:47:32</td>\n",
       "      <td>75</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58074</th>\n",
       "      <td>73713</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1999-02-0705:07:01</td>\n",
       "      <td>465</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77706</th>\n",
       "      <td>117584</td>\n",
       "      <td>590</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1996-09-1108:24:35</td>\n",
       "      <td>255</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating           timestamp  new_movie_id  new_user_id\n",
       "77796  118358     2918     4.0  2005-03-1713:11:50           725          841\n",
       "20109   48345     1907     3.0  2003-01-2605:32:21           345          347\n",
       "61046   25880    74458     4.0  2010-11-2109:47:32            75          180\n",
       "58074   73713       39     4.0  1999-02-0705:07:01           465          522\n",
       "77706  117584      590     4.0  1996-09-1108:24:35           255          831"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>new_movie_id</th>\n",
       "      <th>new_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>9563</td>\n",
       "      <td>480</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996-06-2521:47:44</td>\n",
       "      <td>112</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31667</th>\n",
       "      <td>84140</td>\n",
       "      <td>1682</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2007-07-2207:28:53</td>\n",
       "      <td>54</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38850</th>\n",
       "      <td>103394</td>\n",
       "      <td>1517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1999-12-1216:08:19</td>\n",
       "      <td>569</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78158</th>\n",
       "      <td>132306</td>\n",
       "      <td>1214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2000-08-0318:12:49</td>\n",
       "      <td>139</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57372</th>\n",
       "      <td>63228</td>\n",
       "      <td>2161</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2004-10-1118:51:37</td>\n",
       "      <td>349</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating           timestamp  new_movie_id  new_user_id\n",
       "3750     9563      480     3.0  1996-06-2521:47:44           112           76\n",
       "31667   84140     1682     4.0  2007-07-2207:28:53            54          579\n",
       "38850  103394     1517     1.0  1999-12-1216:08:19           569          725\n",
       "78158  132306     1214     3.0  2000-08-0318:12:49           139          945\n",
       "57372   63228     2161     0.5  2004-10-1118:51:37           349          447"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>new_movie_id</th>\n",
       "      <th>new_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58632</th>\n",
       "      <td>104102</td>\n",
       "      <td>3578</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2013-09-2911:54:04</td>\n",
       "      <td>234</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6501</th>\n",
       "      <td>20257</td>\n",
       "      <td>1284</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1997-02-0601:18:50</td>\n",
       "      <td>861</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45799</th>\n",
       "      <td>125007</td>\n",
       "      <td>2959</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2008-03-2819:43:53</td>\n",
       "      <td>64</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7180</th>\n",
       "      <td>20579</td>\n",
       "      <td>5218</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-03-0519:56:49</td>\n",
       "      <td>379</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>311</td>\n",
       "      <td>546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2001-02-1816:09:41</td>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating           timestamp  new_movie_id  new_user_id\n",
       "58632  104102     3578     5.0  2013-09-2911:54:04           234          731\n",
       "6501    20257     1284     4.0  1997-02-0601:18:50           861          137\n",
       "45799  125007     2959     5.0  2008-03-2819:43:53            64          893\n",
       "7180    20579     5218     4.0  2005-03-0519:56:49           379          145\n",
       "143       311      546     1.0  2001-02-1816:09:41           115            3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training matrix for train\n",
    "ratings_train = np.zeros((n_users, n_movies))\n",
    "\n",
    "for row in X_train.itertuples():\n",
    "    ratings_train[row[6]-1, row[5]-1] = row[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating sparsity of the train matrix\n",
    "sparsity = float(len(ratings_train.nonzero()[0]))\n",
    "sparsity /= (ratings_train.shape[0] * ratings_train.shape[1])\n",
    "sparsity *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.1191"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a similar matrix for both validation and test\n",
    "ratings_validation = np.zeros((n_users, n_movies))\n",
    "for row in X_validation.itertuples():\n",
    "    ratings_validation[row[6]-1, row[5]-1] = row[3]\n",
    "    \n",
    "ratings_test = np.zeros((n_users, n_movies))\n",
    "for row in X_test.itertuples():\n",
    "    ratings_test[row[6]-1, row[5]-1] = row[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Cost Function\n",
    "We will use **mean squared error** to measure the goodness of our model. MSE measures the averaged squared error between the predicted valuesand the actual values. \n",
    "\n",
    "To calculate the MSE, we need two vectors of size [n,1], where $n$ is the number of ratings we are predicting.\n",
    "\n",
    "One vector has the actual ratings, and the other vector has the predictions. \n",
    "\n",
    "We will flatten the sparse matrix with the ratings for the validation set. This will be the vector of actual ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_validation = ratings_validation[ratings_validation.nonzero()].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 1., 3., 5., 4., 3., 2., 3., 2., 1.])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_validation[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Baseline Experiments\n",
    "As a baseline, let's predict an average rating of 3.5 for the validation set and calculate the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_validation = np.zeros((len(X_validation), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_validation[pred_validation==0] = 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.055420084238528"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(pred_validation, actual_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization\n",
    "We will first build a recommendation system using *matrix factorization*, one of the most successful.\n",
    "\n",
    "Matrix factorization decomposes the user-item matrix into a product of two lower dimensionality matrices. \n",
    "\n",
    "Users are represented in lower dimensional latent space, and so are items. \n",
    "\n",
    "Assume our user-item matrix is $R$, with $m$ users and $n$ items. Matrix factorization will create two lower dimensionality matrices, $H$ and $W$. \n",
    "\n",
    "$H$ is an $m$ users $*$ $k$ latent factors matrix. \n",
    "\n",
    "$W$ is a $k$ latent factors $*$ $n$ items matrix. \n",
    "\n",
    "The ratings are computed by matrix multiplication: $R = H * W$\n",
    "\n",
    "The number of $k$ latent factors determines the **capacity** of the model. The higher the $k$, the greater the capacity of the model. By increasing $k$, we can improve the personalization of rating predictions for users, but, if $k$ is too high, the model will **overfit** the data. \n",
    "\n",
    "Matrix factorization learns representations for the users and items in a lower dimensional space and makes predictions based on the newly learned representations. \n",
    "\n",
    "### One Latent Factor\n",
    "We will begin with the simplest form of matrix factorization with just one latent factor. \n",
    "\n",
    "The input is the one-dimensional vector of users for the user embedding and the one-dimensional vector of movies for the movie embedding. \n",
    "\n",
    "We will embed these input vectors into a latent space of one and then flatten them. \n",
    "\n",
    "To generate the output vector product, we will take the dot product of the movie vector and user vector. \n",
    "\n",
    "We will use the *Adam Optimizer* to minimize our cost function: Which will be *mean squared error* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent_factors = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = Input(shape=[1], name='user')\n",
    "\n",
    "user_embedding = Embedding(input_dim=n_users + 1, output_dim=n_latent_factors, name='user_embedding')(user_input)\n",
    "\n",
    "user_vec = Flatten(name='flatten_users')(user_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_input = Input(shape=[1], name='movie')\n",
    "\n",
    "movie_embedding = Embedding(input_dim=n_movies + 1, output_dim=n_latent_factors, name='movie_embedding')(movie_input)\n",
    "\n",
    "movie_vec = Flatten(name='flatten_movies')(movie_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81191 samples, validate on 4511 samples\n",
      "Epoch 1/100\n",
      "81191/81191 [==============================] - 3s 31us/step - loss: 13.3915 - val_loss: 11.4275\n",
      "Epoch 2/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 8.7148 - val_loss: 6.1987\n",
      "Epoch 3/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 4.4242 - val_loss: 3.2204\n",
      "Epoch 4/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 2.4735 - val_loss: 2.0030\n",
      "Epoch 5/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 1.6108 - val_loss: 1.4177\n",
      "Epoch 6/100\n",
      "81191/81191 [==============================] - 2s 27us/step - loss: 1.1816 - val_loss: 1.1238\n",
      "Epoch 7/100\n",
      "81191/81191 [==============================] - 2s 27us/step - loss: 0.9646 - val_loss: 0.9726\n",
      "Epoch 8/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.8534 - val_loss: 0.8920\n",
      "Epoch 9/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7953 - val_loss: 0.8490\n",
      "Epoch 10/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7648 - val_loss: 0.8260\n",
      "Epoch 11/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7483 - val_loss: 0.8146\n",
      "Epoch 12/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7394 - val_loss: 0.8071\n",
      "Epoch 13/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7348 - val_loss: 0.8045\n",
      "Epoch 14/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7318 - val_loss: 0.8015\n",
      "Epoch 15/100\n",
      "81191/81191 [==============================] - 2s 27us/step - loss: 0.7304 - val_loss: 0.8002\n",
      "Epoch 16/100\n",
      "81191/81191 [==============================] - 2s 27us/step - loss: 0.7294 - val_loss: 0.7995\n",
      "Epoch 17/100\n",
      "81191/81191 [==============================] - 2s 27us/step - loss: 0.7289 - val_loss: 0.7986\n",
      "Epoch 18/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7285 - val_loss: 0.7996\n",
      "Epoch 19/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7282 - val_loss: 0.7979\n",
      "Epoch 20/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7281 - val_loss: 0.7973\n",
      "Epoch 21/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7282 - val_loss: 0.7983\n",
      "Epoch 22/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7280 - val_loss: 0.7976\n",
      "Epoch 23/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7281 - val_loss: 0.8001\n",
      "Epoch 24/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7279 - val_loss: 0.7981\n",
      "Epoch 25/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7280 - val_loss: 0.7979\n",
      "Epoch 26/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7278 - val_loss: 0.7989\n",
      "Epoch 27/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7279 - val_loss: 0.7990\n",
      "Epoch 28/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7279 - val_loss: 0.7978\n",
      "Epoch 29/100\n",
      "81191/81191 [==============================] - 2s 31us/step - loss: 0.7279 - val_loss: 0.7984\n",
      "Epoch 30/100\n",
      "81191/81191 [==============================] - 3s 31us/step - loss: 0.7278 - val_loss: 0.7983\n",
      "Epoch 31/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7278 - val_loss: 0.7984\n",
      "Epoch 32/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7277 - val_loss: 0.7974\n",
      "Epoch 33/100\n",
      "81191/81191 [==============================] - 2s 31us/step - loss: 0.7279 - val_loss: 0.7982\n",
      "Epoch 34/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7278 - val_loss: 0.7985\n",
      "Epoch 35/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7278 - val_loss: 0.7998\n",
      "Epoch 36/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7277 - val_loss: 0.7978\n",
      "Epoch 37/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7277 - val_loss: 0.7984\n",
      "Epoch 38/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7278 - val_loss: 0.7977\n",
      "Epoch 39/100\n",
      "81191/81191 [==============================] - 2s 31us/step - loss: 0.7277 - val_loss: 0.7975\n",
      "Epoch 40/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7277 - val_loss: 0.7966\n",
      "Epoch 41/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7278 - val_loss: 0.7976\n",
      "Epoch 42/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7277 - val_loss: 0.7980\n",
      "Epoch 43/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7278 - val_loss: 0.7976\n",
      "Epoch 44/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7278 - val_loss: 0.7980\n",
      "Epoch 45/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7278 - val_loss: 0.7976\n",
      "Epoch 46/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7277 - val_loss: 0.7977\n",
      "Epoch 47/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7278 - val_loss: 0.7985\n",
      "Epoch 48/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7277 - val_loss: 0.7987\n",
      "Epoch 49/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7278 - val_loss: 0.7983\n",
      "Epoch 50/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7277 - val_loss: 0.7984\n",
      "Epoch 51/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7277 - val_loss: 0.7984\n",
      "Epoch 52/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7277 - val_loss: 0.7981\n",
      "Epoch 53/100\n",
      "81191/81191 [==============================] - 3s 32us/step - loss: 0.7277 - val_loss: 0.7975\n",
      "Epoch 54/100\n",
      "81191/81191 [==============================] - 3s 34us/step - loss: 0.7276 - val_loss: 0.7983\n",
      "Epoch 55/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7978\n",
      "Epoch 56/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7976\n",
      "Epoch 57/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7966\n",
      "Epoch 58/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.7277 - val_loss: 0.7974\n",
      "Epoch 59/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.7278 - val_loss: 0.7983\n",
      "Epoch 60/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.7279 - val_loss: 0.7981\n",
      "Epoch 61/100\n",
      "81191/81191 [==============================] - 3s 38us/step - loss: 0.7277 - val_loss: 0.7973\n",
      "Epoch 62/100\n",
      "81191/81191 [==============================] - 3s 39us/step - loss: 0.7277 - val_loss: 0.7964\n",
      "Epoch 63/100\n",
      "81191/81191 [==============================] - 3s 40us/step - loss: 0.7278 - val_loss: 0.7980\n",
      "Epoch 64/100\n",
      "81191/81191 [==============================] - 3s 42us/step - loss: 0.7277 - val_loss: 0.7966\n",
      "Epoch 65/100\n",
      "81191/81191 [==============================] - 3s 42us/step - loss: 0.7278 - val_loss: 0.7977\n",
      "Epoch 66/100\n",
      "81191/81191 [==============================] - 4s 44us/step - loss: 0.7277 - val_loss: 0.7985\n",
      "Epoch 67/100\n",
      "81191/81191 [==============================] - 4s 46us/step - loss: 0.7277 - val_loss: 0.7973\n",
      "Epoch 68/100\n",
      "81191/81191 [==============================] - 4s 48us/step - loss: 0.7277 - val_loss: 0.7976\n",
      "Epoch 69/100\n",
      "81191/81191 [==============================] - 4s 48us/step - loss: 0.7276 - val_loss: 0.7979\n",
      "Epoch 70/100\n",
      "81191/81191 [==============================] - 4s 47us/step - loss: 0.7278 - val_loss: 0.7969\n",
      "Epoch 71/100\n",
      "81191/81191 [==============================] - 4s 48us/step - loss: 0.7278 - val_loss: 0.7982\n",
      "Epoch 72/100\n",
      "81191/81191 [==============================] - 4s 51us/step - loss: 0.7279 - val_loss: 0.7988\n",
      "Epoch 73/100\n",
      "81191/81191 [==============================] - 4s 51us/step - loss: 0.7278 - val_loss: 0.7978\n",
      "Epoch 74/100\n",
      "81191/81191 [==============================] - 4s 49us/step - loss: 0.7278 - val_loss: 0.7960\n",
      "Epoch 75/100\n",
      "81191/81191 [==============================] - 4s 52us/step - loss: 0.7277 - val_loss: 0.7974\n",
      "Epoch 76/100\n",
      "81191/81191 [==============================] - 4s 50us/step - loss: 0.7278 - val_loss: 0.7973\n",
      "Epoch 77/100\n",
      "81191/81191 [==============================] - 4s 49us/step - loss: 0.7278 - val_loss: 0.7974\n",
      "Epoch 78/100\n",
      "81191/81191 [==============================] - 4s 47us/step - loss: 0.7277 - val_loss: 0.7982\n",
      "Epoch 79/100\n",
      "81191/81191 [==============================] - 4s 43us/step - loss: 0.7276 - val_loss: 0.7982\n",
      "Epoch 80/100\n",
      "81191/81191 [==============================] - 3s 42us/step - loss: 0.7278 - val_loss: 0.7985\n",
      "Epoch 81/100\n",
      "81191/81191 [==============================] - 3s 43us/step - loss: 0.7276 - val_loss: 0.7986\n",
      "Epoch 82/100\n",
      "81191/81191 [==============================] - 3s 42us/step - loss: 0.7277 - val_loss: 0.7995\n",
      "Epoch 83/100\n",
      "81191/81191 [==============================] - 3s 43us/step - loss: 0.7277 - val_loss: 0.7981\n",
      "Epoch 84/100\n",
      "81191/81191 [==============================] - 4s 44us/step - loss: 0.7277 - val_loss: 0.7967\n",
      "Epoch 85/100\n",
      "81191/81191 [==============================] - 4s 43us/step - loss: 0.7278 - val_loss: 0.7969\n",
      "Epoch 86/100\n",
      "81191/81191 [==============================] - 3s 42us/step - loss: 0.7278 - val_loss: 0.7986\n",
      "Epoch 87/100\n",
      "81191/81191 [==============================] - 3s 41us/step - loss: 0.7277 - val_loss: 0.7981\n",
      "Epoch 88/100\n",
      "81191/81191 [==============================] - 3s 40us/step - loss: 0.7276 - val_loss: 0.7970\n",
      "Epoch 89/100\n",
      "81191/81191 [==============================] - 3s 38us/step - loss: 0.7277 - val_loss: 0.7979\n",
      "Epoch 90/100\n",
      "81191/81191 [==============================] - 3s 37us/step - loss: 0.7276 - val_loss: 0.7973\n",
      "Epoch 91/100\n",
      "81191/81191 [==============================] - 3s 37us/step - loss: 0.7278 - val_loss: 0.7980\n",
      "Epoch 92/100\n",
      "81191/81191 [==============================] - 3s 38us/step - loss: 0.7277 - val_loss: 0.7972\n",
      "Epoch 93/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7960\n",
      "Epoch 94/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7973\n",
      "Epoch 95/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.7276 - val_loss: 0.7980\n",
      "Epoch 96/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.7278 - val_loss: 0.7975\n",
      "Epoch 97/100\n",
      "81191/81191 [==============================] - 3s 34us/step - loss: 0.7277 - val_loss: 0.7978\n",
      "Epoch 98/100\n",
      "81191/81191 [==============================] - 3s 34us/step - loss: 0.7277 - val_loss: 0.7976\n",
      "Epoch 99/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.7276 - val_loss: 0.7977\n",
      "Epoch 100/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.7277 - val_loss: 0.7980\n"
     ]
    }
   ],
   "source": [
    "# Output representing the predicted ratings \n",
    "product = dot([movie_vec, user_vec], axes=1)\n",
    "\n",
    "# instantiating model\n",
    "model = Model(inputs=[user_input, movie_input], outputs=product)\n",
    "\n",
    "# compiling out model with loss and error\n",
    "model.compile('adam', 'mean_squared_error')\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    x=[X_train['new_user_id'], X_train['new_movie_id']],\n",
    "    y = X_train['rating'],\n",
    "    epochs = 100,\n",
    "    validation_data=([X_validation['new_user_id'], X_validation['new_movie_id']], X_validation['rating']),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Function\n",
    "def lr_plot(history_):\n",
    "    # Plotting our loss with epochs\n",
    "    pd.Series(history_.history['val_loss'][10:]).plot(logy=False)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Error')\n",
    "    print('Minimum MSE: ', min(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum MSE:  0.7959770727807681\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three Latent Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def latent_test(n_latent_factors):\n",
    "    user_input = Input(shape=[1], name='user')\n",
    "\n",
    "    user_embedding = Embedding(input_dim=n_users + 1, output_dim=n_latent_factors, name='user_embedding')(user_input)\n",
    "\n",
    "    user_vec = Flatten(name='flatten_users')(user_embedding)\n",
    "\n",
    "    movie_input = Input(shape=[1], name='movie')\n",
    "\n",
    "    movie_embedding = Embedding(input_dim=n_movies + 1, output_dim=n_latent_factors, name='movie_embedding')(movie_input)\n",
    "\n",
    "    movie_vec = Flatten(name='flatten_movies')(movie_embedding)\n",
    "    \n",
    "    return movie_vec, user_vec, user_input, movie_input\n",
    "\n",
    "def train_model(movie_vec_, user_vec_, user_input_, movie_input_):\n",
    "    # Output representing the predicted ratings \n",
    "    product = dot([movie_vec_, user_vec_], axes=1)\n",
    "\n",
    "    # instantiating model\n",
    "    model = Model(inputs=[user_input_, movie_input_], outputs=product)\n",
    "\n",
    "    # compiling out model with loss and error\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        x=[X_train['new_user_id'], X_train['new_movie_id']],\n",
    "        y = X_train['rating'],\n",
    "        epochs = 100,\n",
    "        validation_data=([X_validation['new_user_id'], X_validation['new_movie_id']], X_validation['rating']),\n",
    "        verbose = 1\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81191 samples, validate on 4511 samples\n",
      "Epoch 1/100\n",
      "81191/81191 [==============================] - 3s 31us/step - loss: 12.9379 - val_loss: 9.0822\n",
      "Epoch 2/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 5.1066 - val_loss: 2.7730\n",
      "Epoch 3/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 1.9078 - val_loss: 1.4248\n",
      "Epoch 4/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 1.1164 - val_loss: 1.0136\n",
      "Epoch 5/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.8648 - val_loss: 0.8738\n",
      "Epoch 6/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7809 - val_loss: 0.8248\n",
      "Epoch 7/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7522 - val_loss: 0.8079\n",
      "Epoch 8/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7420 - val_loss: 0.8032\n",
      "Epoch 9/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7377 - val_loss: 0.8022\n",
      "Epoch 10/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7355 - val_loss: 0.7984\n",
      "Epoch 11/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7348 - val_loss: 0.7983\n",
      "Epoch 12/100\n",
      "81191/81191 [==============================] - 2s 27us/step - loss: 0.7339 - val_loss: 0.7998\n",
      "Epoch 13/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7331 - val_loss: 0.8006\n",
      "Epoch 14/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7324 - val_loss: 0.7995\n",
      "Epoch 15/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7319 - val_loss: 0.7976\n",
      "Epoch 16/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7307 - val_loss: 0.7965\n",
      "Epoch 17/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7295 - val_loss: 0.7961\n",
      "Epoch 18/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7280 - val_loss: 0.7950\n",
      "Epoch 19/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7265 - val_loss: 0.7982\n",
      "Epoch 20/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7246 - val_loss: 0.7953\n",
      "Epoch 21/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7224 - val_loss: 0.7928\n",
      "Epoch 22/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7197 - val_loss: 0.7891\n",
      "Epoch 23/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7170 - val_loss: 0.7896\n",
      "Epoch 24/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7140 - val_loss: 0.7907\n",
      "Epoch 25/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7103 - val_loss: 0.7835\n",
      "Epoch 26/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7065 - val_loss: 0.7835\n",
      "Epoch 27/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7030 - val_loss: 0.7831\n",
      "Epoch 28/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6986 - val_loss: 0.7794\n",
      "Epoch 29/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.6944 - val_loss: 0.7779\n",
      "Epoch 30/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6905 - val_loss: 0.7766\n",
      "Epoch 31/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6866 - val_loss: 0.7733\n",
      "Epoch 32/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6827 - val_loss: 0.7693\n",
      "Epoch 33/100\n",
      "81191/81191 [==============================] - 3s 31us/step - loss: 0.6787 - val_loss: 0.7697\n",
      "Epoch 34/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6753 - val_loss: 0.7667\n",
      "Epoch 35/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6719 - val_loss: 0.7663\n",
      "Epoch 36/100\n",
      "81191/81191 [==============================] - 3s 32us/step - loss: 0.6683 - val_loss: 0.7662\n",
      "Epoch 37/100\n",
      "81191/81191 [==============================] - 2s 31us/step - loss: 0.6657 - val_loss: 0.7667\n",
      "Epoch 38/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6626 - val_loss: 0.7637\n",
      "Epoch 39/100\n",
      "81191/81191 [==============================] - 3s 31us/step - loss: 0.6595 - val_loss: 0.7627\n",
      "Epoch 40/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.6572 - val_loss: 0.7622\n",
      "Epoch 41/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6545 - val_loss: 0.7622\n",
      "Epoch 42/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6523 - val_loss: 0.7616\n",
      "Epoch 43/100\n",
      "81191/81191 [==============================] - 2s 31us/step - loss: 0.6503 - val_loss: 0.7616\n",
      "Epoch 44/100\n",
      "81191/81191 [==============================] - 3s 31us/step - loss: 0.6482 - val_loss: 0.7633\n",
      "Epoch 45/100\n",
      "81191/81191 [==============================] - 3s 31us/step - loss: 0.6461 - val_loss: 0.7609\n",
      "Epoch 46/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.6446 - val_loss: 0.7592\n",
      "Epoch 47/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6429 - val_loss: 0.7614\n",
      "Epoch 48/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6414 - val_loss: 0.7570\n",
      "Epoch 49/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6401 - val_loss: 0.7601\n",
      "Epoch 50/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.6389 - val_loss: 0.7602\n",
      "Epoch 51/100\n",
      "81191/81191 [==============================] - 3s 32us/step - loss: 0.6379 - val_loss: 0.7607\n",
      "Epoch 52/100\n",
      "81191/81191 [==============================] - 3s 34us/step - loss: 0.6365 - val_loss: 0.7613\n",
      "Epoch 53/100\n",
      "81191/81191 [==============================] - 3s 34us/step - loss: 0.6355 - val_loss: 0.7615\n",
      "Epoch 54/100\n",
      "81191/81191 [==============================] - 3s 33us/step - loss: 0.6345 - val_loss: 0.7621\n",
      "Epoch 55/100\n",
      "81191/81191 [==============================] - 3s 33us/step - loss: 0.6334 - val_loss: 0.7622\n",
      "Epoch 56/100\n",
      "81191/81191 [==============================] - 3s 33us/step - loss: 0.6330 - val_loss: 0.7604\n",
      "Epoch 57/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.6319 - val_loss: 0.7622\n",
      "Epoch 58/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.6312 - val_loss: 0.7592\n",
      "Epoch 59/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.6303 - val_loss: 0.7630\n",
      "Epoch 60/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.6298 - val_loss: 0.7624\n",
      "Epoch 61/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.6293 - val_loss: 0.7623\n",
      "Epoch 62/100\n",
      "81191/81191 [==============================] - 3s 37us/step - loss: 0.6284 - val_loss: 0.7631\n",
      "Epoch 63/100\n",
      "81191/81191 [==============================] - 3s 38us/step - loss: 0.6281 - val_loss: 0.7643\n",
      "Epoch 64/100\n",
      "81191/81191 [==============================] - 3s 39us/step - loss: 0.6276 - val_loss: 0.7638\n",
      "Epoch 65/100\n",
      "81191/81191 [==============================] - 3s 40us/step - loss: 0.6269 - val_loss: 0.7641\n",
      "Epoch 66/100\n",
      "81191/81191 [==============================] - 3s 40us/step - loss: 0.6265 - val_loss: 0.7646\n",
      "Epoch 67/100\n",
      "81191/81191 [==============================] - 3s 40us/step - loss: 0.6258 - val_loss: 0.7655\n",
      "Epoch 68/100\n",
      "81191/81191 [==============================] - 3s 42us/step - loss: 0.6256 - val_loss: 0.7646\n",
      "Epoch 69/100\n",
      "81191/81191 [==============================] - 3s 41us/step - loss: 0.6252 - val_loss: 0.7638\n",
      "Epoch 70/100\n",
      "81191/81191 [==============================] - 3s 41us/step - loss: 0.6249 - val_loss: 0.7631\n",
      "Epoch 71/100\n",
      "81191/81191 [==============================] - 3s 42us/step - loss: 0.6242 - val_loss: 0.7633\n",
      "Epoch 72/100\n",
      "81191/81191 [==============================] - 3s 43us/step - loss: 0.6240 - val_loss: 0.7653\n",
      "Epoch 73/100\n",
      "81191/81191 [==============================] - 4s 43us/step - loss: 0.6236 - val_loss: 0.7629\n",
      "Epoch 74/100\n",
      "81191/81191 [==============================] - 3s 43us/step - loss: 0.6233 - val_loss: 0.7651\n",
      "Epoch 75/100\n",
      "81191/81191 [==============================] - 4s 45us/step - loss: 0.6229 - val_loss: 0.7657\n",
      "Epoch 76/100\n",
      "81191/81191 [==============================] - 4s 43us/step - loss: 0.6226 - val_loss: 0.7680\n",
      "Epoch 77/100\n",
      "81191/81191 [==============================] - 3s 43us/step - loss: 0.6221 - val_loss: 0.7685\n",
      "Epoch 78/100\n",
      "81191/81191 [==============================] - 3s 42us/step - loss: 0.6220 - val_loss: 0.7675\n",
      "Epoch 79/100\n",
      "81191/81191 [==============================] - 3s 40us/step - loss: 0.6218 - val_loss: 0.7674\n",
      "Epoch 80/100\n",
      "81191/81191 [==============================] - 3s 42us/step - loss: 0.6213 - val_loss: 0.7689\n",
      "Epoch 81/100\n",
      "81191/81191 [==============================] - 3s 41us/step - loss: 0.6213 - val_loss: 0.7671\n",
      "Epoch 82/100\n",
      "81191/81191 [==============================] - 3s 39us/step - loss: 0.6209 - val_loss: 0.7667\n",
      "Epoch 83/100\n",
      "81191/81191 [==============================] - 3s 39us/step - loss: 0.6206 - val_loss: 0.7707\n",
      "Epoch 84/100\n",
      "81191/81191 [==============================] - 3s 40us/step - loss: 0.6204 - val_loss: 0.7691\n",
      "Epoch 85/100\n",
      "81191/81191 [==============================] - 3s 38us/step - loss: 0.6202 - val_loss: 0.7698\n",
      "Epoch 86/100\n",
      "81191/81191 [==============================] - 3s 37us/step - loss: 0.6201 - val_loss: 0.7695\n",
      "Epoch 87/100\n",
      "81191/81191 [==============================] - 3s 37us/step - loss: 0.6195 - val_loss: 0.7678\n",
      "Epoch 88/100\n",
      "81191/81191 [==============================] - 3s 37us/step - loss: 0.6197 - val_loss: 0.7715\n",
      "Epoch 89/100\n",
      "81191/81191 [==============================] - 3s 38us/step - loss: 0.6195 - val_loss: 0.7724\n",
      "Epoch 90/100\n",
      "81191/81191 [==============================] - 3s 37us/step - loss: 0.6192 - val_loss: 0.7718\n",
      "Epoch 91/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.6189 - val_loss: 0.7719\n",
      "Epoch 92/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.6189 - val_loss: 0.7729\n",
      "Epoch 93/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.6186 - val_loss: 0.7726\n",
      "Epoch 94/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.6184 - val_loss: 0.7722\n",
      "Epoch 95/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.6180 - val_loss: 0.7729\n",
      "Epoch 96/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.6180 - val_loss: 0.7742\n",
      "Epoch 97/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.6182 - val_loss: 0.7759\n",
      "Epoch 98/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.6177 - val_loss: 0.7755\n",
      "Epoch 99/100\n",
      "81191/81191 [==============================] - 3s 34us/step - loss: 0.6175 - val_loss: 0.7774\n",
      "Epoch 100/100\n",
      "81191/81191 [==============================] - 3s 33us/step - loss: 0.6172 - val_loss: 0.7768\n",
      "Minimum MSE:  0.7570331420504156\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VMe1wPHfWfXeAQl1EL2KbtPdcMVOXCDucXdc4tgvcZKX2LGTvDhx4hY77r0bl+BeKMYYDIjehQChQpNAvZd5f+wVllBbgVa7ks7387kf7d479+6RVtLZmbkzI8YYlFJKqbbYXB2AUkop96fJQimlVLs0WSillGqXJgullFLt0mShlFKqXZoslFJKtUuThVJKqXZpslBKKdUuTRZKKaXa5enqADpLZGSkSUxMdHUYSinVraxduzbfGBPVXrkekywSExNJS0tzdRhKKdWtiMg+R8ppM5RSSql2abJQSinVLk0WSiml2qXJQimlVLs0WSillGqXJgullFLt0mShlFKqXb0iWazIyGftvgJXh6GUUt2WU5OFiMwRkZ0ikiEi97ZwPF5ElojIehHZJCLnNDr2W+u8nSJy1onG8NnmA1zxwiquemEV+46UnehllFKqV3NashARD+BJ4GxgGDBfRIYdV+x/gXeNMWOBecBT1rnDrOfDgTnAU9b1OmTxjkPc8dZ6RsWG4mET7nh7AzV19Sf+TSmlVC/lzJrFRCDDGLPHGFMNvA3MPa6MAYKtxyHAfuvxXOBtY0yVMWYvkGFdz2HfZ+Rz8+vrGBYTzKvXTeRvPx3FxuxCHv0m/YS/IaWU6q2cmSz6A9mNnudY+xq7H7hCRHKAz4DbO3AuInKjiKSJSFpeXt6x/euzCrj+lTSSIgJ45dqJBPt6cc7IaC4bH8dTS3ezcveRk/7mlFKqN3F1B/d84GVjTCxwDvCaiDgckzHmWWPMeGPM+Kgo+6SJtXX1/Ob9TYQHePP69ZMIC/A+Vv6+C4aRFBHAXe9soKCsupO/FaWU6rmcmSxygbhGz2OtfY1dB7wLYIxZCfgCkQ6e26K31mSTfqiUP5w3jKggnybH/L09eXz+WPJLq3hs0a6OfC9KKdWrOTNZrAFSRCRJRLyxd1gvPK5MFnAagIgMxZ4s8qxy80TER0SSgBRgdXsvWFRRw7++2snk5HDOGt63xTIj+odw3qhoFqzNoaSy5kS/N6WU6lWcliyMMbXAbcCXwHbsdz1tFZEHROQCq9jdwA0ishF4C7jG2G3FXuPYBnwB/MIYU9feaz6xaBeFFTX84bxhiEir5a49NYnSqloWrM05qe9RKaV6CzHGuDqGTjFyTKqpPPfP/GRsLA9dPKrd8hc99T0FZdUsvnsmNlvriUUppXoyEVlrjBnfXjlXd3B3moNFlXh72Lj7rEEOlb/21CQyj5SzNP2wkyNTSqnur8cki+LKGn4xeyB9gnwdKn/2iH70Dfbhpe8zT+p19x0po6fUzpRSqjU9JllEBHjz81OTHC7v5WHjyskJfLcrn12HSk7oNTdmFzLjH0tZtF1rJ0qpnq3HJIuYUD98vTo2I8j8ifF4e9p4eUXmCb3m4h32JPHl1oMndL5SSnUXPSZZnIiIQB/mjo7hg3W5JzRI7/uMfACWpudRX69NUUqpnqtXJwuA66YlUV1Xz+8/2tyhvoeSyhrWZxcSH+5PXkkVW/cXOzFKpZRyrV6fLIb0C+Z/zhrMZ5sP8vqqLIfPW7XnKHX1hv85azAisGSn9lsopXquXp8sAG6clszMwVE8+Mk2tu4vcuic5Rn5+HrZOGNYX0bFhh7rv1BKqZ5IkwVgswn/vGQ0Yf5e3P7mekqrats95/uMfCYkhuPr5cHswX3YmFPIkdKqLohWKaW6niYLS0SgD4/NG0vmkTLueXcjh4srWy17qLiSXYdLmTowEoBZQ6IwBr5Nz2v1HKWU6s40WTQyOTmCX88ZwhdbDzLlb4u54dU0vtl2iNrjVtdbvst+F9TUFHuyGBETQmSgjzZFKaV6LE9XB+Bubp4xgDOH9eXdtBwWrM3h622HGJ8Qxps3TMbb055bv8/IJzzAm6H97Iv82WzCzMFRfLX1ILV19Xh6aA5WSvUs+l+tBclRgdx79hBW/nY2f7loBGn7CvjrZ9sBMMawPCOfUwZENJmAcPaQPhRX1rIuq9BVYSullNNozaINXh42Lp+UwJ68Ml5YvpdxCWEM6RfE4ZKqY/0VDaamROJpE5bsPMzEpHAXRayUUs6hNQsH3Hv2EMYlhHHv+5t4ZWUm8GN/RYNgXy/GJ4axRPstlFI9kCYLB3h52HjyZ6n4ennw+g9ZJEb4Exvm36zc7CF92HGwhOyj5S6IUimlnEeThYP6hfjy2LyxiMC0lKgWy5w9IhqATzcf6MrQlFLK6TRZdMDUlEg+uOUUfnVGywssxYX7Mzo2hE83abJQSvUsmiw6aGx8GGEB3q0eP3dUNJtzi8g6ok1RSqmeQ5NFJztnpDZFKaV6Hk0WnSw2zJ8xcaF8unm/q0NRSqlOo8nCCc4bFc2W3GIy88tcHYpSSnUKTRZOcLY2RSmlehhNFk7QP9SP1PhQvStKKdVjaLJwknNHxbDtQDF78kpdHYpSSp00TRZOcs7IfgB8pk1RSqkeQJOFk0SH+DEuIYwvth50dShKKXXSNFk40akDIti2v5gyB5ZpVUopd6bJwonGJoRRb2Bjjq5xoZTq3jRZOFFqXBgA6/YVuDgSpZQ6OZosnCjE34sBUQG6ep5SqtvTZOFkqfFhrM8qwBjj6lCUUuqEabJwstSEMArKa9irU38opboxTRZONi7B6rfQpiilVDemycLJBkYFEuTrybos7eRWSnVfmiyczGYTxsSFtntHVGVNHWsyj3ZRVEop1TFOTRYiMkdEdopIhojc28LxR0Rkg7Wli0hho2MPicgWa7vMmXE6W2p8GOmHSiiprGnxuDGGu9/byCVPr+RgUWUXR6eUUu1zWrIQEQ/gSeBsYBgwX0SGNS5jjLnLGDPGGDMGeAL4wDr3XCAVGANMAu4RkWBnxepsqQ2D87KLWjz+1ursYzPUZhfocqxKKffjzJrFRCDDGLPHGFMNvA3MbaP8fOAt6/EwYJkxptYYUwZsAuY4MVanGhMXCtBiv8WOg8X86eOtDOwTCMD+wooujU0ppRzhzGTRH8hu9DzH2teMiCQAScBia9dGYI6I+ItIJDALiGvhvBtFJE1E0vLy8jo1+M4U4udFSp/AZsmivLqW295cT5CvF89fNR6A/YXaDKWUcj/u0sE9D1hgjKkDMMZ8BXwGrMBe21gJ1B1/kjHmWWPMeGPM+KioqK6Mt8PGJYSxPquQ+nr74DxjDPcv3MruvFIevWwMiZEBBPt6cqBIaxZKKffjzGSRS9PaQKy1ryXz+LEJCgBjzF+s/owzAAHSnRJlF0mND6OoooY9+WWsyMjnoqdW8G5aDrfOHMDUlEgAYkL9tGahlHJLnk689hogRUSSsCeJecDPji8kIkOAMOy1h4Z9HkCoMeaIiIwCRgFfOTFWp0tNsPdbXPvyarKPVhAd4stDPx3JJeN+zKf2ZKE1C6WU+3FasjDG1IrIbcCXgAfwojFmq4g8AKQZYxZaRecBb5umkyd5Ad+JCEAxcIUxplsvCpEcGUjfYB9KK2v533OHcsXkBHy9PJqUiQ7xZb0O3lNKuSFn1iwwxnyGve+h8b4/Hvf8/hbOq8R+R1SPYbMJn94xDT8vDwJ8Wv6xx4T6UVBeQ0V1HX7eHi2WUUopV3CXDu5eITLQp9VEARAT6gvAfu3kVkq5GU0WbiQ6xA+AA9rJrZRyM5os3Ej/UHuy0E5upZS70WThRvoG+yKizVBKKfejycKNeHvaiAz00ZqFUsrtaLJwMzGhfhzQmWeVUm6mzWQhds3mZFLOExPiqzULpZTbaTNZWAPlPmurjOpcDVN+NB2jqJRSruVIM9Q6EZng9EgUYB/FXVFTR1FFywslKaWUKzgygnsScLmI7APKsE/qZ4wxo5waWS/VcPtsbmEFof7eLo5GKaXsHEkWZzk9CnVMdOiPA/OGx4S4OBqllLJrtxnKGLMPCAXOt7ZQa59ygpgQ+5Qfuq6FUsqdtJssRORO4A2gj7W9LiK3Ozuw3ioy0AcvDyFXp/xQSrkRR5qhrgMmWWthIyIPYV974glnBtZb2WxCvxBfrVkopdyKI3dDCU2XNK2z9ikniQnRRZCUUu7FkZrFS8AqEfnQen4h8ILzQlIxoX6s3nvU1WEopdQx7SYLY8y/RGQpMNXada0xZr1To+rlokN8OVhcSV29wcOmlTillOu1mSystbC3GmOGAOu6JiQVE+pHXb0hr6SKftbdUUop5UrtTfdRB+wUkfguikehK+YppdyPI30WYcBWEVmNfQQ3AMaYC5wWVS8X02gRpNT4MBdHo5RSjiWLPzg9CtWELq+qlHI3jvRZ3G+MmdVF8Sgg2NeTQB9PcvX2WaWUm3Ckz6JeRHSSoi4kIkTrwDyllBtxpBmqFNgsIl/TtM/iDqdFpYi2xlpc+cIq8kqqyC+tZnhMMLfOHMCk5AhXh6eU6mUcSRYfWJvqQqcN6cOevFKKK2uJDfNnRP8Qlu48zGXP/sCExDB+MWsgMwZFIaLjMJRSzietrcgmIsHGmOJWjsUbY7KcGlkHjR8/3qSlpbk6DKeqqK7jnTVZPLNsDweKKnn6ilTmjIh2dVhKqW5MRNYaY8a3V66tPouljS626LhjH51gXOok+Hl7cM2pSXz7P7MI9vXk2/Q8V4eklOol2koWjds3wts4prqYt6eNMfFhrM8qdHUoSqleoq1kYVp53NJz1cVS40PZeaiEkkpdq1sp5XxtdXD3EZFfYa9FNDzGeh7l9MhUm8bGh2EMbMwuYmpKpKvDUUr1cG3VLJ4DgoDARo8bnj/v/NBUW8bEhQKwPqvAxZEopXqDVmsWxpg/dWUgqmNC/LxI6RPIOk0WSqku4MhKecpNjY0PZX12Ia3d/qyUUp1Fk0U3lhofRmF5DXvzy9ovrJRSJ0GTRTeWmmCfvnyd3kKrlHKydqf7EBEf4KdAYuPyxpgHnBeWcsTAqECCfDxZl1XAxeNiXR2OUqoHc6Rm8V9gLlCLfSLBhq1dIjJHRHaKSIaI3NvC8UdEZIO1pYtIYaNjfxeRrSKyXUQeF50EqRmbTRgTH6qD85RSTufIRIKxxpg5Hb2wtRbGk8AZQA6wRkQWGmO2NZQxxtzVqPztwFjr8SnAqcAo6/ByYAaNpiBRdmPjw/j34l2UVtUS6OPI26mUUh3nSM1ihYiMPIFrTwQyjDF7jDHVwNvYayitmQ+8ZT02gC/gDfgAXsChE4ihxxsbH0q9gU3ZWrtQSjmPI8liKrDWak7aJCKbRWSTA+f1B7IbPc+x9jUjIglAErAYwBizElgCHLC2L40x2x14zV4nNc7eyb1ek4VSyokcabc42+lRwDxggbUyHyIyEBgKNPTafi0i04wx3zU+SURuBG4EiI+P74Iw3U+IvxcDogJYt08H5ymlnKfdmoUxZh8QCpxvbaHWvvbkAnGNnsda+1oyjx+boAAuAn4wxpQaY0qBz4EpLcT2rDFmvDFmfFRU752uamx8mA7OU0o5VbvJQkTuBN4A+ljb61ZndHvWACkikiQi3tgTwsIWrj8ECANWNtqdBcwQEU8R8cLeua3NUK0YlxDG0bJqbYpSSjmNI30W1wGTjDF/NMb8EZgM3NDeScaYWuA24Evs/+jfNcZsFZEHROSCRkXnAW+bph+LFwC7gc3ARmCjMeZjh76jXui8UdFEBnrz10+3a+1CKeUUjvRZCFDX6HkdDi5+ZIz5DPjsuH1/PO75/S2cVwfc5MhrKAjy9eKeMwdz7web+WTTAc4fHePqkJRSPYwjNYuXgFUicr+I3A/8ALzg1KhUh10yPo6h0cH87fMdVNbUtX+CUkp1gCMd3P8CrgWOWtu1xphHnR2Y6hgPm3Df+cPILazg2WV7XB2OUqqHaTVZiEiw9TUcyARet7Z91j7lZiYnR3D2iH78Z+luDhZVujocpVQP0lbN4k3r61ogrdHW8Fy5od+dM5S6esNDX+xwdShKqR6k1WRhjDnP+ppkjElutCUZY5K7LkTVEXHh/twwPYkP1+fyfUa+q8NRSvUQjoyzWOTIPuU+bp+dQmKEP7/9YDMV1drZrZT60YneANNWn4Wv1TcRKSJhIhJubYm0MseTcg++Xh78309GkXW0nEe/SXd1OEopN7Fy9xGG3/clv/9wM2VVtR06t62axU3Y+yeGWF8btv8C/z7BWFUXmTIggvkT43juuz1syS1ydThKKTfwn2934+Np483VWcx5bBk/7Dni8Llt9Vk8ZoxJAu5p1FeRZIwZbYzRZNEN3Hv2UCICffj1gk3U1NW7OhyllAvtPFjCsvQ8fjFrIO/eNAWbCPOf+8Hh8x0ZZ/GEiIwQkUtF5KqG7aSiVl0ixM+LB+cOZ9uBYl76fq+rw1FKudCLy/fi62XjZxPjmZAYzud3TuPKyQkOn+9IB/d9wBPWNgv4O3BBmycptzFnRDQTEsP4aP1+V4eilHKRvJIqPtyQy8XjYgkL8AbA39uTB+aOcPgajkz3cTFwGnDQGHMtMBoIOYF4lYtMHRjF9oPFFJXXuDoUpZQLvP7DPqpr6/n5qUknfA1HkkWFMaYeqLVGdR+m6ToVys1NTg7HGFidedTVoSilnGxN5lEW7zhEfb19BurKmjpe/2Efpw/tQ3JU4Alf15FZZ9NEJBR4DvvdUKU0XXtCubnRcaF4e9pYtecIZwzr6+pwlFJOUlxZw3Uvr6G4spYh/YL4xayBFFfWcKSsmuumntxY6naThTHmVuvh0yLyBRBsjHFkDW7lJny9PBgbF8oPex2/TU4p1f28tnIfxZW13HPmID7asJ/b31oPwPCYYCYnn9yUfq0mCxFJbeuYMWbdSb2y6lKTkyN4YvEuiipqCPHzcnU4SqlOVl5dywvL9zJzcBS3zU7h1pkD+WLrQV7/YR83zRiAiEPLELWqrZrFP62vvsB47CvWCTAK+0SCzdbEVu5rUnI4jy2CtMyjnDZUm6KU6mneXJXF0bJqbp89EACbTThnZDTnjIzulOu3NShvljFmFnAASDXGjDfGjAPGArmd8uqqy6TGh+HtYWPVXu3kVqqnqayp49lle5iSHMG4BOesIOHI3VCDjTGbG54YY7YAQ50SjXIaXy8PxsSFsqoDw/uVUt3De2tzOFxSdaxW4QyOJItNIvK8iMy0tucA7eDuhiYlh7M5t4iSSh1voVRPUV1bz9NLd5MaH8qUARFOex1HksW1wFbgTmvbZu1T3cykpAjqDaTtK3B1KEqpTvLBuhxyCyu4/bSUk+7Ebosjt85WAo9Ym+rGUhNC8fIQVu05yqzBfVwdjlLqJBWUVfP3L3eSGh/KzEFRTn2ttm6dfdcYc6mIbAbM8ceNMaOcGpnqdP7enoyKDe3QtMRKKff1f59vp7iihr9cNNKptQpou2Zxp/X1PKdGoLrUpKRwnlm2h7KqWgJ8HBnAr5RyRz/sOcK7aTncPGMAQ6ODnf56bd06e8D6uq+lzemRKaeYnBxBXb3RfgulurGq2jp+9+FmYsP8uPO0lC55zbaWVS0RkeIWthIRKe6S6FSnG5cQhk1grU4qqFS39fTSPezJK+PPF47Az9ujS16z1XYIY0xQl0SgulSAjycpfYLYmKNLrSrlLj7euJ8lOw9z/ugYpg2MxNOj9RtV1+47ypNLMjh/dAwzu/BGFYcbrUWkD/apPwAwxmQ5JSLldKNiQ/hm+yGMMU7vFFNKtW3F7nzuemcD9cbwwbpcooJ8uGhsfy4ZF0tK3x8/sxtjeO2HfTz4yTaiQ/z4w3ldOzbakZXyLhCRXcBe4FsgE/jcyXEpJxodF0pBeQ05BRWuDkWpHmtFRj47D5a0WWZvfhm3vL6OpMgA1vz+dJ6+IpXRsaG8uHwvZzyyjMueWcnHG/dTVFHDr97dyB//u5VpKVF8fNtU+gT5tnntzuZIzeJBYDLwjTFmrIjMAq5wbljKmUbHhgKwMaeQuHB/F0ejVM/z3w25/PKdDXjahLvPHMyN05Kx2ZrW4ovK7WtPeNiEF66eQESgD3NGRDNnRDT5pVW8l5bDm6v3cftb6/GwCfXGcPcZg/jFrIHNrtUVHEkWNcaYIyJiExGbMWaJiDzq9MiU0wzuF4S3h41NOUWcNyrG1eEo1aN8s+0Qv3p3IxMTwwkP8OZvn+/g2515/PPS0cSE+lFZU0duYQV/+GgL2QXlvHH9ZOIjmn5oiwz04ZaZA7hpejLLduXx1bZDnD2iH9NSnDvwri2OJItCEQkElgFviMhhoMy5YSln8va0MTQmmI3Zha4ORakeZeXuI9z65jpGxATzwjUTCPD24L20HO7/eCtnPrIMf28PDpdUHSv/8CWjmZjU+iyxNpswc3CfLu3Ibo0jyWIuUAncBVwOhAAPODMo5XyjY0NYsDaHunqDhwuqtEr1NJtzirj+lTUkhPvz8rUTCbQGvV46IY5JyeE8+s0uPG1CXLg/sWF+DOkXzLAY5w+m6yxtTffxJPCmMeb7RrtfcX5IqiuMig3l1ZX72J1XyqC+epe0UifrkW/S8ffx5PXrJxEW4N3kWEJEAI9cNsZFkXWOtu6GSgceFpFMEfm7iIztqqCU842JCwHQpiilOkF9vWFdVgGzB/ehb3DX3qXUVdqa7uMxY8wUYAZwBHhRRHaIyH0iMqjLIlROkRwZSKCPJ5t0cJ5SJ21PfhmF5TWkJoS6OhSnaXechTUX1EPGmLHAfOBCYLsjFxeROSKyU0QyROTeFo4/IiIbrC1dRAqt/bMa7d8gIpUicmEHvzfVBptNGNE/mE05WrNQvdfG7ELueW8j1bX1J3WdddZca+MSwjojLLfkyKA8TxE5X0TewD4YbyfwEwfO8wCeBM4GhgHzRWRY4zLGmLuMMWOMMWOAJ4APrP1LGu2fDZQDX3XsW1PtGR0byvYDJSf9h6JUd/XBuhwWrM3h7TUnNyHFuqwCgn09SY4M7KTI3E9bEwmeISIvAjnADcCnwABjzDxjzH8duPZEIMMYs8cYUw28jf3OqtbMB95qYf/FwOfGmHIHXlN1wKjYUKrr6tlxUOeFVL3Tplx7M+zjizIor6494eus3VdAakKYSwbLdZW2aha/BVYAQ40xFxhj3jTGdGR8RX8gu9HzHGtfMyKSACQBi1s4PI+Wk4g6SaNirU5u7bdQvVBNXT3b9hczPiGM/NIqXl6ReULXKaqoYdfhUsbF99wmKGi7g3u2MeZ5Y0xXLHwwD1hgjKlrvFNEooGRwJctnSQiN4pImoik5eXldUGYPUtsmB8RAd5N7ogyxlBf32xhRKV6nJ0HS6iqreeqUxKZPaQPTy/dTVF5zbHjlTV1/OvrdJ5cksGh4spWr7M+y/4vMrUH91eAA30WJyEXiGv0PNba15LWag+XAh8aY2paOIYx5lljzHhjzPioKNcNg++uRIRRsSFsyimksqaOd9ZkceYjy5jx8BLqNGGoHm6z1QQ1OjaEe84cTHFlLc9+txuAA0UVXPL0Sh5ftIt/fLmTU/62mBteTWPJzsMY0/RvY11WITaxT9DZkzlzXc01QIqIJGFPEvOAnx1fSESGAGHAyhauMR97c5hyklGxoSxNz2PqQ0vIL62iT5APh0uq2JhTSGoPr1ar3m1TTiEhfl7Eh/sjIlwwOoYXl2cyKjaU33+4hcqaOp6/ajwD+wTy9ppsFqzN5utth3jopyO5bEL8seus21fAkH7Bx0Zs91ROq1kYY2qB27A3IW0H3jXGbBWRB0TkgkZF5wFvm+PStYgkYq+ZfOusGBVMS4kEYHhMMG9cP4kvfzkdm8C3O7VZT/VsG7OLGBUbcmxNl7vOGER1XT03vbaWAB8PPrz1FE4f1pfEyADuPXsIK+49jTFxoTy+KOPYHYR19Yb1WQU9enxFA6emQmPMZ8Bnx+3743HP72/l3Exa6RBXnWd8YjjbH5iDr9ePSzOOjgvl2/Q87jpDx16q7ufNVVnUGcOVkxNaLVNZU0f6oRJuGpJ8bF9SZAB3npbCjoPF/PWikYT6N52yw9vTxl1nDOLqF1fz3tpsLp+UQPqhEsqq63r0+IoGPbvepBzSOFEAzBgUxWOLdlFQVt1sjhul3Fn20XLuX7gVBM4e0Y/IQJ8Wy207UExtvWFk/6Y1gjtOS2nz+tNTIhkbH8qTizO4eFwsaxsG48W3PnNsT+HMDm7VTc0YFIUx8F1GvqtDUYrPNh9g2t8X8/x3e9ot+8jX6SBQXVvPqyv3tVpuk3UH4GhrjjRHiQh3nT6I/UWVvJeWw7qsAiIDvYkL9+vQdbojTRaqmVGxoYT6e2m/hXKpwyWV3PL6Wm59Yx2FZTX85bPtLNl5uNXy2/YX8+GGXK6bmsTpQ/vy2spMKqrrWiy7KbeIqCAf+p3ApH/TUiIZlxDGk0syWL33KKnxYb1iLXtNFqoZD5swLSWKZbvymt0mqFRX+HrbIc58ZBmLdhzm13MGs+K3sxnSL5g731pPZn7LY4Mf+mIHwb5e3DxjADdMS6KgvIb31+W0WHZTThGj+oec0D95EeGXp6dwoKiSnIKKHj++ooEmC9WiGYOiyCupYvuBthecV6qz1dTVc+/7m+gX7Mtnd0zj1pkDCfL14tkrx2GzCTe9tpayqqZTc6zIyOfb9DxumzWQED8vJiaFMzo2hBeW7202Zqi0qpbdeaWMij3xO5imDoxkvJUkekPnNmiyUK2Ybt1S+226NkWprrU8I58jZdXcdcYgBvb5cWK+uHB/npg/ll2HS7jnvY1k5pdRU1dPfb3hb1/sICbElyun2O+AEhFumJ7M3vwyvtl+qMn1t+QWYQyM6mB/RWMiwn3nD+e8UdHHps3p6fRuKNWiPsG+DIsO5tv0w9wyc4Crw1G9yH/X5xLi58XMwc1nZZiWEsVv5gzh/z7fwedbDmIT6BPky8HiSh6+ZHSTO/vmDO9HbJgfzy3bw1nD+x3b3zAt/6j+J/dPfmRsCP/+WepJXaM70WShWjVjcBTPLdtDaVVtjx+dqtxDWVUtX249xIVj++Pj6dFimRvLIrdeAAAXRklEQVSnJzMpOYJdh0rIOlpO1tFy/Lw8uGhs02FZnh42rpuaxJ8+3saK3fmcMsBeW96YU0T/UD8iWrmtVrVM/wOoVs0YFMV/lu5mRUY+Zzb6ZKaUs3y97RAVNXXN/vE3JiKMiQtljANzMV06Po6nlu7miudX8ZPUWO48LYXNOUUdvmVWaZ+FakNqfBiBPp68viqLw23Mugn2NYhf+2Ef9y/cqndQqRP24fpc+of6Hes8PlkBPp58dsc0rj01iYUb9zPr4aVkHS1vNhhPtU+ThWqVt6eN66clsXyXfaLB3yzYRMbh0mbldh0q4ZJnVvKHj7bw8opM0g81L6NUe/JKqliekc/cMTGduohQVJAPfzhvGMv+ZxbzJ8YT6u/FjEE6S3VHaTOUatMvTx/EhWP68/zyPbyXlsM7adkkRQYwsE8gKX0Cqa03vPT9XgJ8PPndOUP462c7+G5XHoP7Bbk6dNXNfLJpP3X1hgvbaII6Gf1CfHnwwhE8eOEIp1y/p9NkodqVGBnAny8cyS9PH8S7adlsziki43ApS3YcprbeMHdMDH84bxiRgT68syabZbvyuX5acvsXVqqRjzbsZ1h0MIP66gcNd6TJQjksMtCHW2cOPPa8pq6eooqaJpO1TR8UxZursqisqWs2QaFSrdmbX8bG7EJ+d84QV4eiWqF9FuqEeXnYms3qOT0liqraetZkHnVRVOpk5BZWsLmL12QvLK/mwU+2IQIXjNZVCdyVJgvVqSYlh+PlIXy3S2es7W6yj5Zz4ZPf85P/fM+yThi5f7ikkqKKFldEPua7XXmc9egylqXn8b/nDqNfSMcn9lNdQ5OF6lT+3p6MTwjvlH82quscKa3iqhdXU1VTR1JkADe/vvbYSOcTUVtXz0+eWsHd725o8XhNXT33L9zKlS+sJsjXi49+cSrXTU064ddTzqfJQnW66YOi2HGwpN2xGco9lFXV8vOX17C/sIIXr5nA69dNIjzAm2tfWsPeVmZ4bc832w+RU1DB0p15HC2rbnZ8wdocXl6RydVTEvjk9qmMOMmpN5TzabJQna5hXe/luniS26upq+fWN9axObeIf/8slfGJ4fQJ9uXVn0/EAFe9uOqEkv6rK/cR5OtJbb3h8y0Hmh1/Ny2bwX2DuP+C4XojRDehyUJ1umHRwUQEeGtTlJvbdaiEi/+zgm/T8/jrRSM5Y1jfY8eSowJ56ZoJHCmt5mfPdyxh7DpUwordR7h5xgAGRAWwcMP+JsczDpeyPquQi8fF9opFg3oKTRaq09lswtSUSJZn5FNfr1N/dLW3V2dx/8KtHC5p+R98bV09/1m6m3MfX052QQVP/iyVeRPjm5UbHRfKS9dM4EBhBZc+s5L9hRUOvf6rK/fh7Wlj3oQ4Lhjdn9WZRzlY9GMsC9bm4GET5o6NObFvULmEJgvlFNNTosgvrWb7wWJXh9KrpGUe5XcfbublFZnM+sdSnlySQWWNfWnRfUfKeGVFJhc9tYKHvtjBaUP78NVd0zl3VHSr15uUHMGr103iSGk1lz6zkuyj5W2+fkllDR+sy+H8UTFEBPpw/uhojIFPN9ubourqDR+uz2HW4Cj6BOmdT92JJgvlFA39FnoLbdcpqqjhzrc3EBvmz8e3TWVqSiT/+HInsx5eyuyHlzLjH0u5b+FWSqtqeWL+WJ66PLXZOJmWjEsI480bJlNSWcslT69scX6wBh+sy6Wsuo6rrEWIkqMCGdE/mIUb7U1R3+3K41BxFRePi+2cb1p1GU0Wyin6BPsypF8QH63PPfbJVjmPMYbffbiZQ8WVPDZvDCNjQ3jmyvG8feNkEiMCiAv35/7zh7H0npksuWcm54+O6VB/wcjYEN6+cTK19fVc8vQK1mcVtBjDqyszGR0XyuhG04efPyqGjdmFZB0p5721OYT5ezF7SN9m5yv3pslCOc2vzhjEzkMl3P3eRu27cLL30nL4dNMB7jpjEGPjf5zee3JyBG/dOJlXfj6Ra05NIjEy4IRfY2h0MAtuPoUgXy9+9twqlu483OT419sOsTuvjKutWkWD80bb+yZeX7WPr7ceYu6Y/nh76r+e7kbfMeU0Zw7vx2/mDOHTTQd4dNGuTrvunrxSUh/8mhV6ay4AGYdLuG/hVqYkR3DzDOcugZsYGcCCW6aQFBnA9a+k8fS3u3nwk23MengpN762ln7BvpwzsmkfSMP6FM99t4fqunptguqmNFkop7ppejKXjIvl8UW7+Gh9bqdc89+LMzhaVs0bq7M65Xru6NWVmfzp462UV9e2WW5vfhmXP78Kf28PHrlsDB6duA5Ea/oE+fLOTZOZmBTO3z7fwWsr9xEf7s+Dc4ez8PZTWxw3cf7oGIyBIf2CGB4T7PQYVefTWWeVU4kIf7loJPuOlvPrBZsI9PHk9GEn3l69N7+MjzbkEuDtwTfbDvXY9cGf+XYPuYUVfJ+Rz1OXj2Ngn8BmZTLzy5j/7A/U1BneumFyl86rFOTrxcvXTmTL/iIG9w0ioJ334JyR0fz9ix1cMTlBx1Z0U1qzUE7n7WnjmSvGkRjpz/WvpnH9K2vIPMFpJJ5ckoGXh41/XjqGqtp6vtxysJOjdb1DxZXkFlZw7qho8kurmfvv5cfuJmqQmV/GvGd/oLqunrdumOySxaa8PW2kxoe1myjAvlrdqt+fzuWTmo/nUN1Dz/tIptxSWIA3H98+lReXZ/Lvxbs485FlXH1KAiP6h+Dn5YGftwcxoX4MiGr+CbpB1pFyPlyfy9VTEjlreF9iw/z478b9/NSN2sBLq2opKKumoLyagvIaBvcNavETf3294Ye9R5iSHNHsk3bDnUbXTU3iD+cO47Y313HHW+t54ONtBPp4EODjyQFrkNubN0zqNqsS9sQaYG+i757qMj6eHtwycwA/Te3P377YwXPf7W1W5qbpydx95uAW75Z5ckkGHjbhphnJiAhzx8Twn6W7ySupIiqo/fECzlRWVctv3t/EJ5uazoM0pF8Qn985rVlCWLA2h1+/v4kXrxnf7DbSdVmFeHvYGB4TjI+nh/1uphWZ7M4ro6yqlrKqWqJDfLn7zMEM6aft/6praLJQXa5PsC//unQMvz9nKIUVNVRU11FRU8dH63N5Ztkefth7lCfmjSU+wv/YOdlHy3l/XQ5XTE6gb7D9k/qFY/rz5JLdfLJpP9ee6rrprfcdKePGV9ey63AJN0xLIqVPEGEB3uw4UMw/v05naXoeswb3OVa+vt7w9LLdACzdmdc8WewrYHh/e6IA+yJTukytcjVNFsplIgJ9iGg0gnhCYjhTB0bym/c3ce7j33HNqYkE+njiYRO+z8jHJvZaRYOUvkEMiw7mvxtclyy+25XHbW+uB+CVn09kWkrUsWMzBkXx5uosnl66u0my+Gb7IfbklRHi59VsssXq2no25RZx5eSmYxWUcjVNFsqtnD0ympGxIfzqnY08sTijybGfn5pEdIhfk31zx8Twf5/vIDO/rNUBZyt259Mv2JfkNvpDHGGMYWl6Huv3FZB+qJT0QyXsPVLG4L5BPHvl+CY1IbB3AF83NYk/f7qddVkFpFqD5Z5Ztoe4cD+unpLInz/dzr4jZSRE2GPffqCY6tr6Y2WVcheaLJTbiQ3z592bp1BVW0ddvaGmzlBXbwjz92pW9oIxMfztix0s3LifO05LaXa8qKKGn7+8hhmDonjmyvEnHFNlTR2//3AL76/LwSb2wWmD+wXx03GxXHNKYqt3BM2fGM8TizN4eulunr1qPGsyj7J2XwEPzB3O1IGR/PnT7SxLz+PKKfZksc7q3E5NCG3xekq5iiYL5bYa2uzbEh3ix8TEcD7akMvtswc260heuHE/lTX1bMk98dlvcwrKufn1tWzJLeaXp6dw84wBDi/YE+DjyVVTEvj3kgwyDpfyzLe7CfP34pJxcfh62YgL9+Pb9HyunJII2Du3o0N8m9WglHI1HWehur2fpPZnT14ZK3YfaXbsnTX2Ud65hRUUljdf3rM9S3Ye5vwnlrPvSDkvXD2eX54+qMMru119SiLeHjb+96PNfLP9MFefkoiftwciwvSUKFbuzqe6th6wd26PjddahXI/Tk0WIjJHRHaKSIaI3NvC8UdEZIO1pYtIYaNj8SLylYhsF5FtIpLozFhV9zV3TH/6Bfvy2De7MObHCQu35BaxJbeY04fa7zbatt/x2sWW3CKufGEV1760hqggHxbeNpXThp7YyPPIQB8umxDHD3uO4uflwdVWLQLs65WXVdexLquAw9ZgPO2vUO7IaclCRDyAJ4GzgWHAfBEZ1riMMeYuY8wYY8wY4Angg0aHXwX+YYwZCkwEmk5xqZTF18s+fmN15lFWNqpdvLMmGx9PG787ZwgAW9tJFuXVtazcfYTb3lzHeU8sZ3NuEb8/ZygLb5tK0knM1gpww7RkPG3CZRPiCAvwPrb/lAEReNqEb9PzWJdl/6w0VpOFckPO7LOYCGQYY/YAiMjbwFxgWyvl5wP3WWWHAZ7GmK8BjDGtr7aiFHDZhDieWprBo9/sYsqACCpr6vloQy7njowmOSqQvsE+bN1f1Oy8I6VVPPrNLtbuK2DHwWLqDfh5eXD77IHcMD2ZYN/mneonIi7cny9+OZ3YsKZ9EUG+XqQmhLEsPY/6eoO3h40R/XWgnXI/zkwW/YHsRs9zgEktFRSRBCAJWGztGgQUisgH1v5vgHuNMXXHnXcjcCNAfLzOOdOb+Xp5cOvMgdy3cCsrdx/hYHElJZW1XDYhDoDhMSEt1izeW5vDaz/sY+rASG6bNZCx8WGkJoQR4tc5SaKxliYDBPt4jH98uZPKmjqGxQQ71LGvVFdzlw7uecCCRsnAE5gG3ANMAJKBa44/yRjzrDFmvDFmfFRU1PGHVS9z2YQ4+gb78OiiXby9OpukyAAmJoUDMDwmmN15pVRUN121b1l6HkP6BfH69ZP41ZmDmTWkj1MSRVumWwP5dueVaX+FclvOTBa5QFyj57HWvpbMA95q9DwH2GCM2WOMqQU+AlKdEqXqMXy9PLhlxgBW7z3K6syjXDYh7tittMNjgqk3sOPgj7WL8upa0jILmD7ItR80hscEE2H1Y+j4CuWunJks1gApIpIkIt7YE8LC4wuJyBAgDFh53LmhItLwVzyb1vs6lDpm3sR4+gT54GkTfpLa/9j+4TEhQNNO7lV7j1JdV8+0lMguj7Mxm02OxaA1C+WunNZnYYypFZHbgC8BD+BFY8xWEXkASDPGNCSOecDbptE9j8aYOhG5B1gk9o+Ga4HnnBWr6jl8vTx4+JLRZBeU0yfox6nBY8P8CPb1bJIsvkvPx8fTxoTEcFeE2sRNMwaQ0jeImFAdjKfck1NHcBtjPgM+O27fH497fn8r534NjHJacKrHaqlZSUQYFhPMtkZ3RC3blcek5IgOD7JzhqHRwQyN1ruglPtylw5upZxueEwIOw6WUFtXz/7CCjIOlzLdxU1QSnUXOjeU6jWGxwRTVVvP7rwyNmbbB8A1nlJcKdU6rVmoXuPHTu4ilu3Ko0+QD4P6nty05Ur1FposVK8xICoAH08bm3OLWJ6Rz7SUqGaz1CqlWqbJQvUanh42hlgr6xWW1zB9kPZXKOUoTRaqVxkeE8zRMvtU5VMHarJQylGaLFSvMjzGfnvqiP7BTdb/Vkq1TZOF6lUaOrn1LiilOkaThepVRsQEc/OMAVwxOcHVoSjVreg4C9WreHrYuPfsIa4OQ6luR2sWSiml2qXJQimlVLs0WSillGqXJgullFLt0mShlFKqXZoslFJKtUuThVJKqXZpslBKKdUuabT0dbcmIiXATlfH0YJIIN/VQbTAHeNyx5hA4+oId4wJ3DMud4kpwRjT7vw3PWkE905jzHhXB3E8EUnTuBzjjjGBxtUR7hgTuGdc7hhTW7QZSimlVLs0WSillGpXT0oWz7o6gFZoXI5zx5hA4+oId4wJ3DMud4ypVT2mg1sppZTz9KSahVJKKSfpEclCROaIyE4RyRCRe10Yx4siclhEtjTaFy4iX4vILutrWBfHFCciS0Rkm4hsFZE73SQuXxFZLSIbrbj+ZO1PEpFV1nv5joh4d2VcVgweIrJeRD5xo5gyRWSziGwQkTRrn0vfQyuGUBFZICI7RGS7iExxZVwiMtj6GTVsxSLySzf5Wd1l/a5vEZG3rL8Bl/9uOarbJwsR8QCeBM4GhgHzRWSYi8J5GZhz3L57gUXGmBRgkfW8K9UCdxtjhgGTgV9YPx9Xx1UFzDbGjAbGAHNEZDLwEPCIMWYgUABc18VxAdwJbG/03B1iAphljBnT6HZLV7+HAI8BXxhjhgCjsf/cXBaXMWan9TMaA4wDyoEPXRkTgIj0B+4AxhtjRgAewDzc53erfcaYbr0BU4AvGz3/LfBbF8aTCGxp9HwnEG09jsY+HsSVP6//Ame4U1yAP7AOmIR9kJJnS+9tF8USi/2fyWzgE0BcHZP1uplA5HH7XPoeAiHAXqy+T3eJq1EcZwLfu0NMQH8gGwjHPr7tE+Asd/jdcnTr9jULfnwTGuRY+9xFX2PMAevxQaCvqwIRkURgLLAKN4jLau7ZABwGvgZ2A4XGmFqriCvey0eBXwP11vMIN4gJwABfichaEbnR2ufq9zAJyANesprtnheRADeIq8E84C3rsUtjMsbkAg8DWcABoAhYi3v8bjmkJySLbsPYPz645PYzEQkE3gd+aYwpdoe4jDF1xt5cEAtMBFy6OLaInAccNsasdWUcrZhqjEnF3tz6CxGZ3vigi95DTyAV+I8xZixQxnHNO6763bLa/i8A3jv+mCtisvpI5mJPsDFAAM2brN1aT0gWuUBco+ex1j53cUhEogGsr4e7OgAR8cKeKN4wxnzgLnE1MMYUAkuwV8NDRaRhGpqufi9PBS4QkUzgbexNUY+5OCbg2CdTjDGHsbfBT8T172EOkGOMWWU9X4A9ebg6LrAn1XXGmEPWc1fHdDqw1xiTZ4ypAT7A/vvm8t8tR/WEZLEGSLHuKvDGXvVc6OKYGlsIXG09vhp7n0GXEREBXgC2G2P+5UZxRYlIqPXYD3s/ynbsSeNiV8RljPmtMSbWGJOI/fdosTHmclfGBCAiASIS1PAYe1v8Flz8HhpjDgLZIjLY2nUasM3VcVnm82MTFLg+pixgsoj4W3+TDT8rl/5udYirO006qfPoHCAde5v3710Yx1vY2yNrsH/qug57m/ciYBfwDRDexTFNxV7l3gRssLZz3CCuUcB6K64twB+t/cnAaiADexOCj4vey5nAJ+4Qk/X6G61ta8PvuKvfQyuGMUCa9T5+BIS5Oi7sTTxHgJBG+9zhZ/UnYIf1+/4a4OPq362ObDqCWymlVLt6QjOUUkopJ9NkoZRSql2aLJRSSrVLk4VSSql2abJQSinVLk0WSnWAiNQdN6tpp01IJyKJ0mjGYqXciWf7RZRSjVQY+xQlSvUqWrNQqhNY60383VpzYrWIDLT2J4rIYhHZJCKLRCTe2t9XRD601vPYKCKnWJfyEJHnrHUPvrJGtyvlcposlOoYv+OaoS5rdKzIGDMS+Df22WsBngBeMcaMAt4AHrf2Pw58a+zreaRiH5kNkAI8aYwZDhQCP3Xy96OUQ3QEt1IdICKlxpjAFvZnYl/MaY81ceNBY0yEiORjX0ehxtp/wBgTKSJ5QKwxpqrRNRKBr419gR5E5DeAlzHmz87/zpRqm9YslOo8ppXHHVHV6HEd2q+o3IQmC6U6z2WNvq60Hq/APoMtwOXAd9bjRcAtcGwRqJCuClKpE6GfWpTqGD9rdb8GXxhjGm6fDRORTdhrB/OtfbdjX0nuf7CvKnettf9O4FkRuQ57DeIW7DMWK+WWtM9CqU5g9VmMN8bkuzoWpZxBm6GUUkq1S2sWSiml2qU1C6WUUu3SZKGUUqpdmiyUUkq1S5OFUkqpdmmyUEop1S5NFkoppdr1//qCaI9ZQVjQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3 latent factors\n",
    "n_factors = 3\n",
    "\n",
    "# Grabbing out vectors and input\n",
    "movie_vec, user_vec, user_input, movie_input = latent_test(n_factors)\n",
    "\n",
    "# training our model\n",
    "history = train_model(movie_vec, user_vec, user_input, movie_input)\n",
    "\n",
    "# plotting our loss \n",
    "lr_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81191 samples, validate on 4511 samples\n",
      "Epoch 1/100\n",
      "81191/81191 [==============================] - 3s 31us/step - loss: 11.3553 - val_loss: 5.6260\n",
      "Epoch 2/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 2.9670 - val_loss: 1.7057\n",
      "Epoch 3/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 1.2267 - val_loss: 1.0282\n",
      "Epoch 4/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.8633 - val_loss: 0.8600\n",
      "Epoch 5/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7736 - val_loss: 0.8198\n",
      "Epoch 6/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7505 - val_loss: 0.8041\n",
      "Epoch 7/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7437 - val_loss: 0.8014\n",
      "Epoch 8/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7413 - val_loss: 0.8004\n",
      "Epoch 9/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7404 - val_loss: 0.8038\n",
      "Epoch 10/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7397 - val_loss: 0.8022\n",
      "Epoch 11/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7393 - val_loss: 0.7990\n",
      "Epoch 12/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7382 - val_loss: 0.8002\n",
      "Epoch 13/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7369 - val_loss: 0.8019\n",
      "Epoch 14/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7359 - val_loss: 0.7991\n",
      "Epoch 15/100\n",
      "81191/81191 [==============================] - 2s 28us/step - loss: 0.7344 - val_loss: 0.7988\n",
      "Epoch 16/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7323 - val_loss: 0.7987\n",
      "Epoch 17/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7295 - val_loss: 0.7935\n",
      "Epoch 18/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.7259 - val_loss: 0.7950\n",
      "Epoch 19/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7220 - val_loss: 0.7919\n",
      "Epoch 20/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7168 - val_loss: 0.7881\n",
      "Epoch 21/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7111 - val_loss: 0.7838\n",
      "Epoch 22/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.7050 - val_loss: 0.7822\n",
      "Epoch 23/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6981 - val_loss: 0.7787\n",
      "Epoch 24/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6917 - val_loss: 0.7759\n",
      "Epoch 25/100\n",
      "81191/81191 [==============================] - 2s 29us/step - loss: 0.6855 - val_loss: 0.7693\n",
      "Epoch 26/100\n",
      "81191/81191 [==============================] - 2s 31us/step - loss: 0.6789 - val_loss: 0.7707\n",
      "Epoch 27/100\n",
      "81191/81191 [==============================] - 3s 31us/step - loss: 0.6729 - val_loss: 0.7641\n",
      "Epoch 28/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6670 - val_loss: 0.7653\n",
      "Epoch 29/100\n",
      "81191/81191 [==============================] - 3s 31us/step - loss: 0.6608 - val_loss: 0.7665\n",
      "Epoch 30/100\n",
      "81191/81191 [==============================] - 3s 31us/step - loss: 0.6553 - val_loss: 0.7622\n",
      "Epoch 31/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6496 - val_loss: 0.7610\n",
      "Epoch 32/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6439 - val_loss: 0.7594\n",
      "Epoch 33/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6384 - val_loss: 0.7615\n",
      "Epoch 34/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6327 - val_loss: 0.7606\n",
      "Epoch 35/100\n",
      "81191/81191 [==============================] - 2s 31us/step - loss: 0.6277 - val_loss: 0.7638\n",
      "Epoch 36/100\n",
      "81191/81191 [==============================] - 2s 31us/step - loss: 0.6227 - val_loss: 0.7615\n",
      "Epoch 37/100\n",
      "81191/81191 [==============================] - 3s 31us/step - loss: 0.6177 - val_loss: 0.7618\n",
      "Epoch 38/100\n",
      "81191/81191 [==============================] - 2s 31us/step - loss: 0.6137 - val_loss: 0.7631\n",
      "Epoch 39/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6088 - val_loss: 0.7635\n",
      "Epoch 40/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6053 - val_loss: 0.7663\n",
      "Epoch 41/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.6016 - val_loss: 0.7678\n",
      "Epoch 42/100\n",
      "81191/81191 [==============================] - 2s 31us/step - loss: 0.5982 - val_loss: 0.7684\n",
      "Epoch 43/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.5945 - val_loss: 0.7695\n",
      "Epoch 44/100\n",
      "81191/81191 [==============================] - 2s 30us/step - loss: 0.5918 - val_loss: 0.7677\n",
      "Epoch 45/100\n",
      "81191/81191 [==============================] - 3s 31us/step - loss: 0.5893 - val_loss: 0.7709\n",
      "Epoch 46/100\n",
      "81191/81191 [==============================] - 2s 31us/step - loss: 0.5865 - val_loss: 0.7732\n",
      "Epoch 47/100\n",
      "81191/81191 [==============================] - 3s 33us/step - loss: 0.5840 - val_loss: 0.7705\n",
      "Epoch 48/100\n",
      "81191/81191 [==============================] - 3s 34us/step - loss: 0.5820 - val_loss: 0.7774\n",
      "Epoch 49/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.5802 - val_loss: 0.7760\n",
      "Epoch 50/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.5781 - val_loss: 0.7793\n",
      "Epoch 51/100\n",
      "81191/81191 [==============================] - 3s 37us/step - loss: 0.5758 - val_loss: 0.7781\n",
      "Epoch 52/100\n",
      "81191/81191 [==============================] - 3s 37us/step - loss: 0.5746 - val_loss: 0.7808\n",
      "Epoch 53/100\n",
      "81191/81191 [==============================] - 3s 37us/step - loss: 0.5726 - val_loss: 0.7834\n",
      "Epoch 54/100\n",
      "81191/81191 [==============================] - 3s 37us/step - loss: 0.5710 - val_loss: 0.7822\n",
      "Epoch 55/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.5703 - val_loss: 0.7815\n",
      "Epoch 56/100\n",
      "81191/81191 [==============================] - 3s 38us/step - loss: 0.5684 - val_loss: 0.7826\n",
      "Epoch 57/100\n",
      "81191/81191 [==============================] - 3s 39us/step - loss: 0.5672 - val_loss: 0.7835\n",
      "Epoch 58/100\n",
      "81191/81191 [==============================] - 3s 40us/step - loss: 0.5658 - val_loss: 0.7838\n",
      "Epoch 59/100\n",
      "81191/81191 [==============================] - 3s 40us/step - loss: 0.5647 - val_loss: 0.7855\n",
      "Epoch 60/100\n",
      "81191/81191 [==============================] - 3s 43us/step - loss: 0.5636 - val_loss: 0.7854\n",
      "Epoch 61/100\n",
      "81191/81191 [==============================] - 3s 42us/step - loss: 0.5626 - val_loss: 0.7861\n",
      "Epoch 62/100\n",
      "81191/81191 [==============================] - 3s 43us/step - loss: 0.5613 - val_loss: 0.7909\n",
      "Epoch 63/100\n",
      "81191/81191 [==============================] - 4s 44us/step - loss: 0.5605 - val_loss: 0.7890\n",
      "Epoch 64/100\n",
      "81191/81191 [==============================] - 4s 44us/step - loss: 0.5594 - val_loss: 0.7928\n",
      "Epoch 65/100\n",
      "81191/81191 [==============================] - 4s 45us/step - loss: 0.5587 - val_loss: 0.7920\n",
      "Epoch 66/100\n",
      "81191/81191 [==============================] - 3s 43us/step - loss: 0.5579 - val_loss: 0.7887\n",
      "Epoch 67/100\n",
      "81191/81191 [==============================] - 4s 46us/step - loss: 0.5570 - val_loss: 0.7912\n",
      "Epoch 68/100\n",
      "81191/81191 [==============================] - 4s 46us/step - loss: 0.5564 - val_loss: 0.7933\n",
      "Epoch 69/100\n",
      "81191/81191 [==============================] - 4s 47us/step - loss: 0.5556 - val_loss: 0.7924\n",
      "Epoch 70/100\n",
      "81191/81191 [==============================] - 4s 46us/step - loss: 0.5548 - val_loss: 0.7930\n",
      "Epoch 71/100\n",
      "81191/81191 [==============================] - 4s 44us/step - loss: 0.5541 - val_loss: 0.7948\n",
      "Epoch 72/100\n",
      "81191/81191 [==============================] - 4s 43us/step - loss: 0.5535 - val_loss: 0.7941\n",
      "Epoch 73/100\n",
      "81191/81191 [==============================] - 4s 43us/step - loss: 0.5532 - val_loss: 0.7908\n",
      "Epoch 74/100\n",
      "81191/81191 [==============================] - 3s 43us/step - loss: 0.5523 - val_loss: 0.7932\n",
      "Epoch 75/100\n",
      "81191/81191 [==============================] - 3s 41us/step - loss: 0.5522 - val_loss: 0.7948\n",
      "Epoch 76/100\n",
      "81191/81191 [==============================] - 3s 42us/step - loss: 0.5513 - val_loss: 0.7961\n",
      "Epoch 77/100\n",
      "81191/81191 [==============================] - 3s 41us/step - loss: 0.5508 - val_loss: 0.7968\n",
      "Epoch 78/100\n",
      "81191/81191 [==============================] - 3s 41us/step - loss: 0.5502 - val_loss: 0.7965\n",
      "Epoch 79/100\n",
      "81191/81191 [==============================] - 3s 40us/step - loss: 0.5495 - val_loss: 0.7956\n",
      "Epoch 80/100\n",
      "81191/81191 [==============================] - 3s 39us/step - loss: 0.5493 - val_loss: 0.7980\n",
      "Epoch 81/100\n",
      "81191/81191 [==============================] - 3s 40us/step - loss: 0.5488 - val_loss: 0.7993\n",
      "Epoch 82/100\n",
      "81191/81191 [==============================] - 3s 38us/step - loss: 0.5485 - val_loss: 0.7998\n",
      "Epoch 83/100\n",
      "81191/81191 [==============================] - 3s 39us/step - loss: 0.5481 - val_loss: 0.8007\n",
      "Epoch 84/100\n",
      "81191/81191 [==============================] - 3s 38us/step - loss: 0.5473 - val_loss: 0.7998\n",
      "Epoch 85/100\n",
      "81191/81191 [==============================] - 3s 38us/step - loss: 0.5475 - val_loss: 0.7979\n",
      "Epoch 86/100\n",
      "81191/81191 [==============================] - 3s 38us/step - loss: 0.5468 - val_loss: 0.8023\n",
      "Epoch 87/100\n",
      "81191/81191 [==============================] - 3s 37us/step - loss: 0.5463 - val_loss: 0.7997\n",
      "Epoch 88/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.5464 - val_loss: 0.7996\n",
      "Epoch 89/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.5460 - val_loss: 0.8040\n",
      "Epoch 90/100\n",
      "81191/81191 [==============================] - 3s 37us/step - loss: 0.5455 - val_loss: 0.8007\n",
      "Epoch 91/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.5453 - val_loss: 0.8012\n",
      "Epoch 92/100\n",
      "81191/81191 [==============================] - 3s 36us/step - loss: 0.5451 - val_loss: 0.8027\n",
      "Epoch 93/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.5448 - val_loss: 0.8019\n",
      "Epoch 94/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.5446 - val_loss: 0.8040\n",
      "Epoch 95/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.5442 - val_loss: 0.8063\n",
      "Epoch 96/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.5438 - val_loss: 0.8043\n",
      "Epoch 97/100\n",
      "81191/81191 [==============================] - 3s 33us/step - loss: 0.5433 - val_loss: 0.8021\n",
      "Epoch 98/100\n",
      "81191/81191 [==============================] - 3s 34us/step - loss: 0.5435 - val_loss: 0.8050\n",
      "Epoch 99/100\n",
      "81191/81191 [==============================] - 3s 34us/step - loss: 0.5432 - val_loss: 0.8054\n",
      "Epoch 100/100\n",
      "81191/81191 [==============================] - 3s 35us/step - loss: 0.5429 - val_loss: 0.8073\n",
      "Minimum MSE:  0.7593589305904112\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3 latent factors\n",
    "n_factors = 5\n",
    "\n",
    "# Grabbing out vectors and input\n",
    "movie_vec, user_vec, user_input, movie_input = latent_test(n_factors)\n",
    "\n",
    "# training our model\n",
    "history = train_model(movie_vec, user_vec, user_input, movie_input)\n",
    "\n",
    "# plotting our loss \n",
    "lr_plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering Using RBMs\n",
    "Recall that RBMs have two layers: the input/visible layer and the hidden layer. The neurons in each layer communicate with neurons in the other layer but not with neurons in the same layer. \n",
    "\n",
    "There is no intralayer communication among the neurons (restricted).\n",
    "\n",
    "Another important feature of RBMs is that the communication between layers happens in both directions, not just one direction. \n",
    "\n",
    "Example: With autoencoders, the neurons communicate with the next layer, passing information only in a feedforward way. \n",
    "\n",
    "With RBMs, the neurons in the visible layer communicate with the hidden layer, and then the hidden layer passes back information to the visible layer, going back nad forth several times. \n",
    "\n",
    "RBMs perform this communication (back and forth communication) to develop a generative model such taht the reconstructions from the output of the hidden layer are similar to the original inputs. \n",
    "\n",
    "RBMs are trying to create a generative model that will help **predict** whether a user will like a movie that the user has never seen based on how similar the movie is to other movies the user has rated and based on how similar the user is to the other user that have rated the movie. \n",
    "\n",
    "The **visible** layer will have ```X``` neurons, where ```X``` is the number of movies in the dataset. Each neuron will have a normalized rating value from zero to one, where zero means the user has not seen the movie. \n",
    "\n",
    "The closer the normalized rating value is to one, the more the user likes the movie represented by the neuron. \n",
    "\n",
    "*The neurons in the visible layer will communicate with neurons in the hidden layer, which will try to learn the underlying, latent features that characterize the user-movie preference.* \n",
    "\n",
    "### RMB Neuronal Architecture\n",
    "For our example: We have an $M * N$ matrix, with $M$ users and $N$ movies. \n",
    "\n",
    "To train the RBM, we pass along a batch of $k$ users with their $n$ movie ratings into the neural network and train for a certain number of epochs. \n",
    "\n",
    "Each input $x$ that is passed into the neural network represents a single user's rating preference for all $n$ movies, where $n$ is one thousand. Therefor, the visible layer has $n$ nodes, one for each movie. \n",
    "\n",
    "We can specify the number of nodes in the hidden layer, which will generally be fewer than the nodes in the visible layer to force the hidden layer to learn the most salient aspects of the original input as efficiently as possible. \n",
    "\n",
    "*Gibbs sampling*, the activation of hidden layers results in final outputs that are generated stochastically. This level of randomness helps builds a better-performing and more robust generative model. \n",
    "\n",
    "The output after Gibbs sampling $h0$ is passed back through the neural network in the opposite direction in what is called a *backward pass*. \n",
    "\n",
    "In the backward pass, the activations in the *forward pass* after Gibbs sampling are fed into the hidden layer and multiplied by the same weights *W* as before. \n",
    "\n",
    "Forward pass: $f(v0) = W*V0+hb$ where $f$ is the forward pass, $v0$ is the input vector, $W$ are the weights associated with the neurons of that layer (input to hidden), $hb$ is our biased that is added so neurons are sure to fire. \n",
    "\n",
    "Then the product of $f(v0)$ is passed through an **activation function** usually a non-linear activation function. \n",
    "\n",
    "The RBM goes through a series of forward and backward passes like this to learn the optimal weights as its attempt to *build a robust generative model*. \n",
    "\n",
    "RBMs are the first type of *generative learning models*. \n",
    "\n",
    "In essence: By performing Gibbs sampling and retraining weights via forward and backward passes, RBMs are trying to learn the **probability dstribution** of the original input. \n",
    "\n",
    "Specifically, RBMs minimize the ***Kullback-Leibler divergence*** which measures how one probability distribution is different from another. \n",
    "\n",
    "In our case, RBMs are minimizing the probability distribution of the **reconstructed data**. \n",
    "\n",
    "By iteratively readadjusting the weights in the neural net, the RBM learns to *approximate* the original data as best as possible. \n",
    "\n",
    "With this newly learned probability distribution, RBMs are able to make predictions about never-before-seen data. \n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the RBM Class\n",
    "class RBM(object):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, learning_rate, epochs, batchsize):\n",
    "        \n",
    "        # Defining Hyperparameters\n",
    "        self._input_size = input_size\n",
    "        self._output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batchsize = batchsize\n",
    "        \n",
    "        # Initializing weights and biases using zero matrices\n",
    "        self.w = np.zeros([input_size, output_size], 'float')\n",
    "        self.hb = np.zeros([output_size], 'float')\n",
    "        self.vb = np.zeros([input_size], 'float')\n",
    "        \n",
    "    # Forward pass, h is hidden layer, v is visible layer\n",
    "    def prob_h_given_v(self, visible, w, hb):\n",
    "        return tf.nn.sigmoid(tf.matmul(visible, w) + hb)\n",
    "\n",
    "    # Backward pass\n",
    "    def prob_v_given_h(self, hidden, w, vb):\n",
    "        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)\n",
    "\n",
    "    # Sampling function Gibbs\n",
    "    def sample_prob(self, probs):\n",
    "        return tf.nn.relu(tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n",
    "    \n",
    "    # Our Training method\n",
    "    def train(self, X):\n",
    "        \n",
    "        # Placeholders: Weights, Hidden Bias, Visible Bias\n",
    "        _w = tf.placeholder('float', [self._input_size, self._output_size])\n",
    "        _hb = tf.placeholder('float', [self._output_size])\n",
    "        _vb = tf.placeholder('float', [self._input_size])\n",
    "        \n",
    "        # Initializing with zeros\n",
    "        prv_w = np.zeros([self._input_size, self._output_size], 'float')\n",
    "        prv_hb = np.zeros([self._output_size], 'float')\n",
    "        prv_vb = np.zeros([self._input_size], 'float')\n",
    "        \n",
    "        cur_w = np.zeros([self._input_size, self._output_size], 'float')\n",
    "        cur_hb = np.zeros([self._output_size], 'float')\n",
    "        cur_vb = np.zeros([self._input_size], 'float')\n",
    "        \n",
    "        # Placeholder - initializes\n",
    "        v0 = tf.placeholder('float', [None, self._input_size])\n",
    "        \n",
    "        # Forward Pass\n",
    "        h0 = self.sample_prob(self.prob_h_given_v(v0, _w, _hb))\n",
    "        \n",
    "        # Back Pass\n",
    "        v1 = self.sample_prob(self.prob_v_given_h(h0, _w, _vb))\n",
    "        \n",
    "        # Forward pass\n",
    "        h1 = self.prob_h_given_v(v1, _w, _hb)\n",
    "        \n",
    "        # Updating weights\n",
    "        positive_grad = tf.matmul(tf.transpose(v0), h0)\n",
    "        negative_grad = tf.matmul(tf.transpose(v1), h1)\n",
    "        \n",
    "        update_w = _w + self.learning_rate * (positive_grad - negative_grad) / tf.to_float(tf.shape(v0)[0])\n",
    "        update_vb = _vb + self.learning_rate * tf.reduce_mean(v0 - v1, 0)\n",
    "        update_hb = _hb + self.learning_rate * tf.reduce_mean(h0 - h1, 0)\n",
    "        \n",
    "        # error - MSE\n",
    "        err = tf.reduce_mean(tf.square(v0 - v1))\n",
    "        \n",
    "        \"\"\"\n",
    "        During the training, forward and backward passes will be made, and the RBM will update weights based on how the generated data compares to the original input. We will print the reconstruction error from each epoch\n",
    "        \"\"\"\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            for epoch in range(self.epochs):\n",
    "                for start, end in zip(range(0, len(X), self.batchsize), range(self.batchsize, len(X), self.batchsize)):\n",
    "                    \n",
    "                    # Initializing batch - window\n",
    "                    batch = X[start:end]\n",
    "                    \n",
    "                    # Computing weights and biases\n",
    "                    cur_w = sess.run(update_w, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    cur_hb = sess.run(update_hb, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    cur_vb = sess.run(update_vb, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    \n",
    "                    prv_w = cur_w\n",
    "                    prv_hb = cur_hb\n",
    "                    prv_vb = cur_vb\n",
    "                    \n",
    "                # Error\n",
    "                error = sess.run(err, feed_dict={v0: X, _w: cur_w, _vb: cur_vb, _hb: cur_hb})\n",
    "                print(f'Epoch: {epoch}, reconstruction error: {error}')\n",
    "                \n",
    "            # Updating weights biases\n",
    "            self.w = prv_w\n",
    "            self.hb = prv_hb\n",
    "            self.vb = prv_vb\n",
    "            \n",
    "    def rbm_output(self, X):\n",
    "        \n",
    "        input_X = tf.constant(X)\n",
    "        _w = tf.constant(self.w)\n",
    "        _hb = tf.constant(self.hb)\n",
    "        _vb = tf.constant(self.vb)\n",
    "        out = tf.nn.sigmoid(tf.matmul(input_X, _w) + _hb)\n",
    "        hiddenGen = self.sample_prob(self.prob_h_given_v(input_X, _w, _hb))\n",
    "        visibleGen = self.sample_prob(self.prob_v_given_h(hiddenGen, _w, _vb))\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            return sess.run(out), sess.run(visibleGen), sess.run(hiddenGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, reconstruction error: 1.0927095413208008\n",
      "Epoch: 1, reconstruction error: 1.079160451889038\n",
      "Epoch: 2, reconstruction error: 1.0790225267410278\n",
      "Epoch: 3, reconstruction error: 1.0842435359954834\n",
      "Epoch: 4, reconstruction error: 1.0846835374832153\n",
      "Epoch: 5, reconstruction error: 1.0836914777755737\n",
      "Epoch: 6, reconstruction error: 1.0801924467086792\n",
      "Epoch: 7, reconstruction error: 1.0777864456176758\n",
      "Epoch: 8, reconstruction error: 1.0747694969177246\n",
      "Epoch: 9, reconstruction error: 1.0729684829711914\n",
      "Epoch: 10, reconstruction error: 1.0740875005722046\n",
      "Epoch: 11, reconstruction error: 1.0723614692687988\n",
      "Epoch: 12, reconstruction error: 1.0760104656219482\n",
      "Epoch: 13, reconstruction error: 1.077697515487671\n",
      "Epoch: 14, reconstruction error: 1.0775375366210938\n",
      "Epoch: 15, reconstruction error: 1.0741724967956543\n",
      "Epoch: 16, reconstruction error: 1.0787404775619507\n",
      "Epoch: 17, reconstruction error: 1.0732024908065796\n",
      "Epoch: 18, reconstruction error: 1.08559250831604\n",
      "Epoch: 19, reconstruction error: 1.0762624740600586\n",
      "Epoch: 20, reconstruction error: 1.0848544836044312\n",
      "Epoch: 21, reconstruction error: 1.0778834819793701\n",
      "Epoch: 22, reconstruction error: 1.0799554586410522\n",
      "Epoch: 23, reconstruction error: 1.082161545753479\n",
      "Epoch: 24, reconstruction error: 1.0864615440368652\n",
      "Epoch: 25, reconstruction error: 1.0811655521392822\n",
      "Epoch: 26, reconstruction error: 1.0847254991531372\n",
      "Epoch: 27, reconstruction error: 1.0848175287246704\n",
      "Epoch: 28, reconstruction error: 1.0904295444488525\n",
      "Epoch: 29, reconstruction error: 1.0836844444274902\n",
      "Epoch: 30, reconstruction error: 1.0914084911346436\n",
      "Epoch: 31, reconstruction error: 1.0854004621505737\n",
      "Epoch: 32, reconstruction error: 1.0913255214691162\n",
      "Epoch: 33, reconstruction error: 1.086425542831421\n",
      "Epoch: 34, reconstruction error: 1.0901875495910645\n",
      "Epoch: 35, reconstruction error: 1.0929754972457886\n",
      "Epoch: 36, reconstruction error: 1.0912295579910278\n",
      "Epoch: 37, reconstruction error: 1.0904065370559692\n",
      "Epoch: 38, reconstruction error: 1.0887864828109741\n",
      "Epoch: 39, reconstruction error: 1.093314528465271\n",
      "Epoch: 40, reconstruction error: 1.0963964462280273\n",
      "Epoch: 41, reconstruction error: 1.0896004438400269\n",
      "Epoch: 42, reconstruction error: 1.0940314531326294\n",
      "Epoch: 43, reconstruction error: 1.091855525970459\n",
      "Epoch: 44, reconstruction error: 1.091936469078064\n",
      "Epoch: 45, reconstruction error: 1.0911915302276611\n",
      "Epoch: 46, reconstruction error: 1.0924475193023682\n",
      "Epoch: 47, reconstruction error: 1.089516520500183\n",
      "Epoch: 48, reconstruction error: 1.092515468597412\n",
      "Epoch: 49, reconstruction error: 1.0934555530548096\n",
      "Epoch: 50, reconstruction error: 1.0932865142822266\n",
      "Epoch: 51, reconstruction error: 1.0943914651870728\n",
      "Epoch: 52, reconstruction error: 1.096136450767517\n",
      "Epoch: 53, reconstruction error: 1.0957214832305908\n",
      "Epoch: 54, reconstruction error: 1.092718482017517\n",
      "Epoch: 55, reconstruction error: 1.0959885120391846\n",
      "Epoch: 56, reconstruction error: 1.094315528869629\n",
      "Epoch: 57, reconstruction error: 1.0924124717712402\n",
      "Epoch: 58, reconstruction error: 1.095084547996521\n",
      "Epoch: 59, reconstruction error: 1.0946284532546997\n",
      "Epoch: 60, reconstruction error: 1.0959374904632568\n",
      "Epoch: 61, reconstruction error: 1.0942864418029785\n",
      "Epoch: 62, reconstruction error: 1.0941275358200073\n",
      "Epoch: 63, reconstruction error: 1.094219446182251\n",
      "Epoch: 64, reconstruction error: 1.0938334465026855\n",
      "Epoch: 65, reconstruction error: 1.0950485467910767\n",
      "Epoch: 66, reconstruction error: 1.0940074920654297\n",
      "Epoch: 67, reconstruction error: 1.0932224988937378\n",
      "Epoch: 68, reconstruction error: 1.0934494733810425\n",
      "Epoch: 69, reconstruction error: 1.094630479812622\n",
      "Epoch: 70, reconstruction error: 1.0952554941177368\n",
      "Epoch: 71, reconstruction error: 1.0931694507598877\n",
      "Epoch: 72, reconstruction error: 1.0935574769973755\n",
      "Epoch: 73, reconstruction error: 1.093401551246643\n",
      "Epoch: 74, reconstruction error: 1.0945874452590942\n",
      "Epoch: 75, reconstruction error: 1.09208345413208\n",
      "Epoch: 76, reconstruction error: 1.0935815572738647\n",
      "Epoch: 77, reconstruction error: 1.09174644947052\n",
      "Epoch: 78, reconstruction error: 1.093192458152771\n",
      "Epoch: 79, reconstruction error: 1.091713547706604\n",
      "Epoch: 80, reconstruction error: 1.0931315422058105\n",
      "Epoch: 81, reconstruction error: 1.091855525970459\n",
      "Epoch: 82, reconstruction error: 1.0937714576721191\n",
      "Epoch: 83, reconstruction error: 1.09261155128479\n",
      "Epoch: 84, reconstruction error: 1.0935695171356201\n",
      "Epoch: 85, reconstruction error: 1.0936665534973145\n",
      "Epoch: 86, reconstruction error: 1.0914984941482544\n",
      "Epoch: 87, reconstruction error: 1.0930794477462769\n",
      "Epoch: 88, reconstruction error: 1.0931555032730103\n",
      "Epoch: 89, reconstruction error: 1.0918865203857422\n",
      "Epoch: 90, reconstruction error: 1.0920774936676025\n",
      "Epoch: 91, reconstruction error: 1.0934524536132812\n",
      "Epoch: 92, reconstruction error: 1.090577483177185\n",
      "Epoch: 93, reconstruction error: 1.0915985107421875\n",
      "Epoch: 94, reconstruction error: 1.0905455350875854\n",
      "Epoch: 95, reconstruction error: 1.0915465354919434\n",
      "Epoch: 96, reconstruction error: 1.0904874801635742\n",
      "Epoch: 97, reconstruction error: 1.0903534889221191\n",
      "Epoch: 98, reconstruction error: 1.0895905494689941\n",
      "Epoch: 99, reconstruction error: 1.0904945135116577\n",
      "Epoch: 100, reconstruction error: 1.0895805358886719\n",
      "Epoch: 101, reconstruction error: 1.0908575057983398\n",
      "Epoch: 102, reconstruction error: 1.089998483657837\n",
      "Epoch: 103, reconstruction error: 1.0902265310287476\n",
      "Epoch: 104, reconstruction error: 1.089471459388733\n",
      "Epoch: 105, reconstruction error: 1.0903375148773193\n",
      "Epoch: 106, reconstruction error: 1.0898555517196655\n",
      "Epoch: 107, reconstruction error: 1.0894365310668945\n",
      "Epoch: 108, reconstruction error: 1.0896265506744385\n",
      "Epoch: 109, reconstruction error: 1.0889215469360352\n",
      "Epoch: 110, reconstruction error: 1.0894005298614502\n",
      "Epoch: 111, reconstruction error: 1.088462471961975\n",
      "Epoch: 112, reconstruction error: 1.0892025232315063\n",
      "Epoch: 113, reconstruction error: 1.0878194570541382\n",
      "Epoch: 114, reconstruction error: 1.0885825157165527\n",
      "Epoch: 115, reconstruction error: 1.0890485048294067\n",
      "Epoch: 116, reconstruction error: 1.088355541229248\n",
      "Epoch: 117, reconstruction error: 1.087897539138794\n",
      "Epoch: 118, reconstruction error: 1.0881634950637817\n",
      "Epoch: 119, reconstruction error: 1.0870784521102905\n",
      "Epoch: 120, reconstruction error: 1.0882644653320312\n",
      "Epoch: 121, reconstruction error: 1.087491512298584\n",
      "Epoch: 122, reconstruction error: 1.0880515575408936\n",
      "Epoch: 123, reconstruction error: 1.0885474681854248\n",
      "Epoch: 124, reconstruction error: 1.087517499923706\n",
      "Epoch: 125, reconstruction error: 1.0868395566940308\n",
      "Epoch: 126, reconstruction error: 1.0874254703521729\n",
      "Epoch: 127, reconstruction error: 1.087193489074707\n",
      "Epoch: 128, reconstruction error: 1.0875924825668335\n",
      "Epoch: 129, reconstruction error: 1.0864875316619873\n",
      "Epoch: 130, reconstruction error: 1.0876034498214722\n",
      "Epoch: 131, reconstruction error: 1.0862925052642822\n",
      "Epoch: 132, reconstruction error: 1.0871144533157349\n",
      "Epoch: 133, reconstruction error: 1.0867935419082642\n",
      "Epoch: 134, reconstruction error: 1.0866265296936035\n",
      "Epoch: 135, reconstruction error: 1.0862715244293213\n",
      "Epoch: 136, reconstruction error: 1.0858805179595947\n",
      "Epoch: 137, reconstruction error: 1.08560049533844\n",
      "Epoch: 138, reconstruction error: 1.086024522781372\n",
      "Epoch: 139, reconstruction error: 1.0860135555267334\n",
      "Epoch: 140, reconstruction error: 1.085031509399414\n",
      "Epoch: 141, reconstruction error: 1.0855175256729126\n",
      "Epoch: 142, reconstruction error: 1.0857985019683838\n",
      "Epoch: 143, reconstruction error: 1.0851185321807861\n",
      "Epoch: 144, reconstruction error: 1.0857964754104614\n",
      "Epoch: 145, reconstruction error: 1.0851714611053467\n",
      "Epoch: 146, reconstruction error: 1.085295557975769\n",
      "Epoch: 147, reconstruction error: 1.0846974849700928\n",
      "Epoch: 148, reconstruction error: 1.0855724811553955\n",
      "Epoch: 149, reconstruction error: 1.0848824977874756\n",
      "Epoch: 150, reconstruction error: 1.0846644639968872\n",
      "Epoch: 151, reconstruction error: 1.0844894647598267\n",
      "Epoch: 152, reconstruction error: 1.084599494934082\n",
      "Epoch: 153, reconstruction error: 1.08497154712677\n",
      "Epoch: 154, reconstruction error: 1.084794521331787\n",
      "Epoch: 155, reconstruction error: 1.0838375091552734\n",
      "Epoch: 156, reconstruction error: 1.0848745107650757\n",
      "Epoch: 157, reconstruction error: 1.0847054719924927\n",
      "Epoch: 158, reconstruction error: 1.083369493484497\n",
      "Epoch: 159, reconstruction error: 1.0845295190811157\n",
      "Epoch: 160, reconstruction error: 1.0850064754486084\n",
      "Epoch: 161, reconstruction error: 1.0841015577316284\n",
      "Epoch: 162, reconstruction error: 1.0840915441513062\n",
      "Epoch: 163, reconstruction error: 1.0834335088729858\n",
      "Epoch: 164, reconstruction error: 1.0838115215301514\n",
      "Epoch: 165, reconstruction error: 1.0836085081100464\n",
      "Epoch: 166, reconstruction error: 1.0839885473251343\n",
      "Epoch: 167, reconstruction error: 1.0841845273971558\n",
      "Epoch: 168, reconstruction error: 1.0833024978637695\n",
      "Epoch: 169, reconstruction error: 1.0840275287628174\n",
      "Epoch: 170, reconstruction error: 1.083174467086792\n",
      "Epoch: 171, reconstruction error: 1.0846045017242432\n",
      "Epoch: 172, reconstruction error: 1.0833995342254639\n",
      "Epoch: 173, reconstruction error: 1.0839124917984009\n",
      "Epoch: 174, reconstruction error: 1.0828394889831543\n",
      "Epoch: 175, reconstruction error: 1.083058476448059\n",
      "Epoch: 176, reconstruction error: 1.0833524465560913\n",
      "Epoch: 177, reconstruction error: 1.0839015245437622\n",
      "Epoch: 178, reconstruction error: 1.082898497581482\n",
      "Epoch: 179, reconstruction error: 1.0828584432601929\n",
      "Epoch: 180, reconstruction error: 1.0837185382843018\n",
      "Epoch: 181, reconstruction error: 1.0826804637908936\n",
      "Epoch: 182, reconstruction error: 1.0836055278778076\n",
      "Epoch: 183, reconstruction error: 1.0815155506134033\n",
      "Epoch: 184, reconstruction error: 1.0827654600143433\n",
      "Epoch: 185, reconstruction error: 1.0832594633102417\n",
      "Epoch: 186, reconstruction error: 1.0824865102767944\n",
      "Epoch: 187, reconstruction error: 1.0824764966964722\n",
      "Epoch: 188, reconstruction error: 1.0828255414962769\n",
      "Epoch: 189, reconstruction error: 1.0823475122451782\n",
      "Epoch: 190, reconstruction error: 1.0822144746780396\n",
      "Epoch: 191, reconstruction error: 1.082350492477417\n",
      "Epoch: 192, reconstruction error: 1.0816634893417358\n",
      "Epoch: 193, reconstruction error: 1.0820435285568237\n",
      "Epoch: 194, reconstruction error: 1.0818865299224854\n",
      "Epoch: 195, reconstruction error: 1.0811774730682373\n",
      "Epoch: 196, reconstruction error: 1.0827175378799438\n",
      "Epoch: 197, reconstruction error: 1.0814424753189087\n",
      "Epoch: 198, reconstruction error: 1.0817464590072632\n",
      "Epoch: 199, reconstruction error: 1.0816024541854858\n",
      "Epoch: 200, reconstruction error: 1.0812054872512817\n",
      "Epoch: 201, reconstruction error: 1.0818475484848022\n",
      "Epoch: 202, reconstruction error: 1.081750512123108\n",
      "Epoch: 203, reconstruction error: 1.081608533859253\n",
      "Epoch: 204, reconstruction error: 1.0808744430541992\n",
      "Epoch: 205, reconstruction error: 1.0811655521392822\n",
      "Epoch: 206, reconstruction error: 1.080689549446106\n",
      "Epoch: 207, reconstruction error: 1.0814704895019531\n",
      "Epoch: 208, reconstruction error: 1.0809235572814941\n",
      "Epoch: 209, reconstruction error: 1.0807185173034668\n",
      "Epoch: 210, reconstruction error: 1.0816855430603027\n",
      "Epoch: 211, reconstruction error: 1.0805284976959229\n",
      "Epoch: 212, reconstruction error: 1.0809224843978882\n",
      "Epoch: 213, reconstruction error: 1.0810655355453491\n",
      "Epoch: 214, reconstruction error: 1.0804145336151123\n",
      "Epoch: 215, reconstruction error: 1.0805004835128784\n",
      "Epoch: 216, reconstruction error: 1.080946445465088\n",
      "Epoch: 217, reconstruction error: 1.0808894634246826\n",
      "Epoch: 218, reconstruction error: 1.0796115398406982\n",
      "Epoch: 219, reconstruction error: 1.080822467803955\n",
      "Epoch: 220, reconstruction error: 1.0802475214004517\n",
      "Epoch: 221, reconstruction error: 1.0810494422912598\n",
      "Epoch: 222, reconstruction error: 1.0803184509277344\n",
      "Epoch: 223, reconstruction error: 1.0802714824676514\n",
      "Epoch: 224, reconstruction error: 1.080054521560669\n",
      "Epoch: 225, reconstruction error: 1.0801265239715576\n",
      "Epoch: 226, reconstruction error: 1.0803505182266235\n",
      "Epoch: 227, reconstruction error: 1.0794014930725098\n",
      "Epoch: 228, reconstruction error: 1.079824447631836\n",
      "Epoch: 229, reconstruction error: 1.0801844596862793\n",
      "Epoch: 230, reconstruction error: 1.0796804428100586\n",
      "Epoch: 231, reconstruction error: 1.0798795223236084\n",
      "Epoch: 232, reconstruction error: 1.079817533493042\n",
      "Epoch: 233, reconstruction error: 1.0794425010681152\n",
      "Epoch: 234, reconstruction error: 1.079683542251587\n",
      "Epoch: 235, reconstruction error: 1.0794445276260376\n",
      "Epoch: 236, reconstruction error: 1.0795414447784424\n",
      "Epoch: 237, reconstruction error: 1.0797295570373535\n",
      "Epoch: 238, reconstruction error: 1.079269528388977\n",
      "Epoch: 239, reconstruction error: 1.0798205137252808\n",
      "Epoch: 240, reconstruction error: 1.0791164636611938\n",
      "Epoch: 241, reconstruction error: 1.0793424844741821\n",
      "Epoch: 242, reconstruction error: 1.0789874792099\n",
      "Epoch: 243, reconstruction error: 1.0792574882507324\n",
      "Epoch: 244, reconstruction error: 1.0788735151290894\n",
      "Epoch: 245, reconstruction error: 1.0790455341339111\n",
      "Epoch: 246, reconstruction error: 1.0789484977722168\n",
      "Epoch: 247, reconstruction error: 1.0786174535751343\n",
      "Epoch: 248, reconstruction error: 1.0791494846343994\n",
      "Epoch: 249, reconstruction error: 1.0790385007858276\n",
      "Epoch: 250, reconstruction error: 1.0788655281066895\n",
      "Epoch: 251, reconstruction error: 1.0790435075759888\n",
      "Epoch: 252, reconstruction error: 1.0800114870071411\n",
      "Epoch: 253, reconstruction error: 1.0789084434509277\n",
      "Epoch: 254, reconstruction error: 1.0788885354995728\n",
      "Epoch: 255, reconstruction error: 1.0786495208740234\n",
      "Epoch: 256, reconstruction error: 1.0790425539016724\n",
      "Epoch: 257, reconstruction error: 1.0789254903793335\n",
      "Epoch: 258, reconstruction error: 1.0782614946365356\n",
      "Epoch: 259, reconstruction error: 1.0785125494003296\n",
      "Epoch: 260, reconstruction error: 1.0784075260162354\n",
      "Epoch: 261, reconstruction error: 1.078365445137024\n",
      "Epoch: 262, reconstruction error: 1.0772705078125\n",
      "Epoch: 263, reconstruction error: 1.0788154602050781\n",
      "Epoch: 264, reconstruction error: 1.0785285234451294\n",
      "Epoch: 265, reconstruction error: 1.0778534412384033\n",
      "Epoch: 266, reconstruction error: 1.0780595541000366\n",
      "Epoch: 267, reconstruction error: 1.0782455205917358\n",
      "Epoch: 268, reconstruction error: 1.078046441078186\n",
      "Epoch: 269, reconstruction error: 1.0785855054855347\n",
      "Epoch: 270, reconstruction error: 1.078392505645752\n",
      "Epoch: 271, reconstruction error: 1.0783125162124634\n",
      "Epoch: 272, reconstruction error: 1.0777205228805542\n",
      "Epoch: 273, reconstruction error: 1.0787044763565063\n",
      "Epoch: 274, reconstruction error: 1.0775854587554932\n",
      "Epoch: 275, reconstruction error: 1.0784565210342407\n",
      "Epoch: 276, reconstruction error: 1.0770134925842285\n",
      "Epoch: 277, reconstruction error: 1.0777565240859985\n",
      "Epoch: 278, reconstruction error: 1.0770454406738281\n",
      "Epoch: 279, reconstruction error: 1.0776565074920654\n",
      "Epoch: 280, reconstruction error: 1.0774065256118774\n",
      "Epoch: 281, reconstruction error: 1.0779814720153809\n",
      "Epoch: 282, reconstruction error: 1.0779725313186646\n",
      "Epoch: 283, reconstruction error: 1.0776524543762207\n",
      "Epoch: 284, reconstruction error: 1.0769685506820679\n",
      "Epoch: 285, reconstruction error: 1.0778495073318481\n",
      "Epoch: 286, reconstruction error: 1.0776724815368652\n",
      "Epoch: 287, reconstruction error: 1.077771544456482\n",
      "Epoch: 288, reconstruction error: 1.0772044658660889\n",
      "Epoch: 289, reconstruction error: 1.07755446434021\n",
      "Epoch: 290, reconstruction error: 1.076873540878296\n",
      "Epoch: 291, reconstruction error: 1.077917456626892\n",
      "Epoch: 292, reconstruction error: 1.0774915218353271\n",
      "Epoch: 293, reconstruction error: 1.0777854919433594\n",
      "Epoch: 294, reconstruction error: 1.0769344568252563\n",
      "Epoch: 295, reconstruction error: 1.077723503112793\n",
      "Epoch: 296, reconstruction error: 1.076796531677246\n",
      "Epoch: 297, reconstruction error: 1.0773495435714722\n",
      "Epoch: 298, reconstruction error: 1.0770864486694336\n",
      "Epoch: 299, reconstruction error: 1.0771665573120117\n",
      "Epoch: 300, reconstruction error: 1.0770925283432007\n",
      "Epoch: 301, reconstruction error: 1.0772714614868164\n",
      "Epoch: 302, reconstruction error: 1.0775394439697266\n",
      "Epoch: 303, reconstruction error: 1.0769104957580566\n",
      "Epoch: 304, reconstruction error: 1.0770984888076782\n",
      "Epoch: 305, reconstruction error: 1.0776615142822266\n",
      "Epoch: 306, reconstruction error: 1.0766685009002686\n",
      "Epoch: 307, reconstruction error: 1.077486515045166\n",
      "Epoch: 308, reconstruction error: 1.0773154497146606\n",
      "Epoch: 309, reconstruction error: 1.0772465467453003\n",
      "Epoch: 310, reconstruction error: 1.0776665210723877\n",
      "Epoch: 311, reconstruction error: 1.0772994756698608\n",
      "Epoch: 312, reconstruction error: 1.0774755477905273\n",
      "Epoch: 313, reconstruction error: 1.0769845247268677\n",
      "Epoch: 314, reconstruction error: 1.076817512512207\n",
      "Epoch: 315, reconstruction error: 1.0771855115890503\n",
      "Epoch: 316, reconstruction error: 1.076980471611023\n",
      "Epoch: 317, reconstruction error: 1.0774544477462769\n",
      "Epoch: 318, reconstruction error: 1.077641487121582\n",
      "Epoch: 319, reconstruction error: 1.0769624710083008\n",
      "Epoch: 320, reconstruction error: 1.0774664878845215\n",
      "Epoch: 321, reconstruction error: 1.077364444732666\n",
      "Epoch: 322, reconstruction error: 1.0768685340881348\n",
      "Epoch: 323, reconstruction error: 1.0774184465408325\n",
      "Epoch: 324, reconstruction error: 1.076669454574585\n",
      "Epoch: 325, reconstruction error: 1.0767395496368408\n",
      "Epoch: 326, reconstruction error: 1.0767375230789185\n",
      "Epoch: 327, reconstruction error: 1.0767534971237183\n",
      "Epoch: 328, reconstruction error: 1.0769644975662231\n",
      "Epoch: 329, reconstruction error: 1.0763205289840698\n",
      "Epoch: 330, reconstruction error: 1.0771994590759277\n",
      "Epoch: 331, reconstruction error: 1.0768455266952515\n",
      "Epoch: 332, reconstruction error: 1.0766195058822632\n",
      "Epoch: 333, reconstruction error: 1.0770595073699951\n",
      "Epoch: 334, reconstruction error: 1.0766735076904297\n",
      "Epoch: 335, reconstruction error: 1.076891541481018\n",
      "Epoch: 336, reconstruction error: 1.0767154693603516\n",
      "Epoch: 337, reconstruction error: 1.076195478439331\n",
      "Epoch: 338, reconstruction error: 1.0766174793243408\n",
      "Epoch: 339, reconstruction error: 1.076972484588623\n",
      "Epoch: 340, reconstruction error: 1.0764554738998413\n",
      "Epoch: 341, reconstruction error: 1.0766345262527466\n",
      "Epoch: 342, reconstruction error: 1.0769925117492676\n",
      "Epoch: 343, reconstruction error: 1.076770544052124\n",
      "Epoch: 344, reconstruction error: 1.0763264894485474\n",
      "Epoch: 345, reconstruction error: 1.077378511428833\n",
      "Epoch: 346, reconstruction error: 1.076783537864685\n",
      "Epoch: 347, reconstruction error: 1.0766675472259521\n",
      "Epoch: 348, reconstruction error: 1.076891541481018\n",
      "Epoch: 349, reconstruction error: 1.0767874717712402\n",
      "Epoch: 350, reconstruction error: 1.0769104957580566\n",
      "Epoch: 351, reconstruction error: 1.076061487197876\n",
      "Epoch: 352, reconstruction error: 1.0764094591140747\n",
      "Epoch: 353, reconstruction error: 1.0767065286636353\n",
      "Epoch: 354, reconstruction error: 1.0768334865570068\n",
      "Epoch: 355, reconstruction error: 1.0763665437698364\n",
      "Epoch: 356, reconstruction error: 1.0765055418014526\n",
      "Epoch: 357, reconstruction error: 1.0764094591140747\n",
      "Epoch: 358, reconstruction error: 1.0767954587936401\n",
      "Epoch: 359, reconstruction error: 1.0763754844665527\n",
      "Epoch: 360, reconstruction error: 1.076938509941101\n",
      "Epoch: 361, reconstruction error: 1.0754995346069336\n",
      "Epoch: 362, reconstruction error: 1.0769305229187012\n",
      "Epoch: 363, reconstruction error: 1.0763394832611084\n",
      "Epoch: 364, reconstruction error: 1.0766774415969849\n",
      "Epoch: 365, reconstruction error: 1.0759764909744263\n",
      "Epoch: 366, reconstruction error: 1.0762865543365479\n",
      "Epoch: 367, reconstruction error: 1.0766104459762573\n",
      "Epoch: 368, reconstruction error: 1.0764164924621582\n",
      "Epoch: 369, reconstruction error: 1.0756975412368774\n",
      "Epoch: 370, reconstruction error: 1.0765204429626465\n",
      "Epoch: 371, reconstruction error: 1.0755014419555664\n",
      "Epoch: 372, reconstruction error: 1.0760624408721924\n",
      "Epoch: 373, reconstruction error: 1.075980544090271\n",
      "Epoch: 374, reconstruction error: 1.0766844749450684\n",
      "Epoch: 375, reconstruction error: 1.076317548751831\n",
      "Epoch: 376, reconstruction error: 1.075479507446289\n",
      "Epoch: 377, reconstruction error: 1.0759705305099487\n",
      "Epoch: 378, reconstruction error: 1.0761804580688477\n",
      "Epoch: 379, reconstruction error: 1.075764536857605\n",
      "Epoch: 380, reconstruction error: 1.0758274793624878\n",
      "Epoch: 381, reconstruction error: 1.0761125087738037\n",
      "Epoch: 382, reconstruction error: 1.0760984420776367\n",
      "Epoch: 383, reconstruction error: 1.076406478881836\n",
      "Epoch: 384, reconstruction error: 1.0765204429626465\n",
      "Epoch: 385, reconstruction error: 1.0763845443725586\n",
      "Epoch: 386, reconstruction error: 1.0761164426803589\n",
      "Epoch: 387, reconstruction error: 1.0760935544967651\n",
      "Epoch: 388, reconstruction error: 1.0759395360946655\n",
      "Epoch: 389, reconstruction error: 1.0762134790420532\n",
      "Epoch: 390, reconstruction error: 1.076027512550354\n",
      "Epoch: 391, reconstruction error: 1.0756934881210327\n",
      "Epoch: 392, reconstruction error: 1.07577645778656\n",
      "Epoch: 393, reconstruction error: 1.0762394666671753\n",
      "Epoch: 394, reconstruction error: 1.0754845142364502\n",
      "Epoch: 395, reconstruction error: 1.0758475065231323\n",
      "Epoch: 396, reconstruction error: 1.0754724740982056\n",
      "Epoch: 397, reconstruction error: 1.0755444765090942\n",
      "Epoch: 398, reconstruction error: 1.0760904550552368\n",
      "Epoch: 399, reconstruction error: 1.0761034488677979\n",
      "Epoch: 400, reconstruction error: 1.075271487236023\n",
      "Epoch: 401, reconstruction error: 1.0759614706039429\n",
      "Epoch: 402, reconstruction error: 1.075150489807129\n",
      "Epoch: 403, reconstruction error: 1.07590651512146\n",
      "Epoch: 404, reconstruction error: 1.075202465057373\n",
      "Epoch: 405, reconstruction error: 1.075850486755371\n",
      "Epoch: 406, reconstruction error: 1.075629472732544\n",
      "Epoch: 407, reconstruction error: 1.0755234956741333\n",
      "Epoch: 408, reconstruction error: 1.0752365589141846\n",
      "Epoch: 409, reconstruction error: 1.075940489768982\n",
      "Epoch: 410, reconstruction error: 1.075263500213623\n",
      "Epoch: 411, reconstruction error: 1.075574517250061\n",
      "Epoch: 412, reconstruction error: 1.0751254558563232\n",
      "Epoch: 413, reconstruction error: 1.0754765272140503\n",
      "Epoch: 414, reconstruction error: 1.0754984617233276\n",
      "Epoch: 415, reconstruction error: 1.0758384466171265\n",
      "Epoch: 416, reconstruction error: 1.074979543685913\n",
      "Epoch: 417, reconstruction error: 1.0750545263290405\n",
      "Epoch: 418, reconstruction error: 1.0751885175704956\n",
      "Epoch: 419, reconstruction error: 1.075392484664917\n",
      "Epoch: 420, reconstruction error: 1.0750654935836792\n",
      "Epoch: 421, reconstruction error: 1.0752995014190674\n",
      "Epoch: 422, reconstruction error: 1.075263500213623\n",
      "Epoch: 423, reconstruction error: 1.0747824907302856\n",
      "Epoch: 424, reconstruction error: 1.0754435062408447\n",
      "Epoch: 425, reconstruction error: 1.0749704837799072\n",
      "Epoch: 426, reconstruction error: 1.0746815204620361\n",
      "Epoch: 427, reconstruction error: 1.0752445459365845\n",
      "Epoch: 428, reconstruction error: 1.0751545429229736\n",
      "Epoch: 429, reconstruction error: 1.0750994682312012\n",
      "Epoch: 430, reconstruction error: 1.0753874778747559\n",
      "Epoch: 431, reconstruction error: 1.0748075246810913\n",
      "Epoch: 432, reconstruction error: 1.0748635530471802\n",
      "Epoch: 433, reconstruction error: 1.0750725269317627\n",
      "Epoch: 434, reconstruction error: 1.0750075578689575\n",
      "Epoch: 435, reconstruction error: 1.075263500213623\n",
      "Epoch: 436, reconstruction error: 1.0752404928207397\n",
      "Epoch: 437, reconstruction error: 1.0749424695968628\n",
      "Epoch: 438, reconstruction error: 1.075055480003357\n",
      "Epoch: 439, reconstruction error: 1.0748244524002075\n",
      "Epoch: 440, reconstruction error: 1.0749125480651855\n",
      "Epoch: 441, reconstruction error: 1.0746395587921143\n",
      "Epoch: 442, reconstruction error: 1.0747334957122803\n",
      "Epoch: 443, reconstruction error: 1.0744035243988037\n",
      "Epoch: 444, reconstruction error: 1.0750174522399902\n",
      "Epoch: 445, reconstruction error: 1.074684500694275\n",
      "Epoch: 446, reconstruction error: 1.0745974779129028\n",
      "Epoch: 447, reconstruction error: 1.074399471282959\n",
      "Epoch: 448, reconstruction error: 1.0748294591903687\n",
      "Epoch: 449, reconstruction error: 1.0747264623641968\n",
      "Epoch: 450, reconstruction error: 1.0747034549713135\n",
      "Epoch: 451, reconstruction error: 1.0746204853057861\n",
      "Epoch: 452, reconstruction error: 1.0745664834976196\n",
      "Epoch: 453, reconstruction error: 1.0747414827346802\n",
      "Epoch: 454, reconstruction error: 1.0745885372161865\n",
      "Epoch: 455, reconstruction error: 1.074460506439209\n",
      "Epoch: 456, reconstruction error: 1.0750484466552734\n",
      "Epoch: 457, reconstruction error: 1.0748674869537354\n",
      "Epoch: 458, reconstruction error: 1.0743415355682373\n",
      "Epoch: 459, reconstruction error: 1.0747164487838745\n",
      "Epoch: 460, reconstruction error: 1.074499487876892\n",
      "Epoch: 461, reconstruction error: 1.0743074417114258\n",
      "Epoch: 462, reconstruction error: 1.0753434896469116\n",
      "Epoch: 463, reconstruction error: 1.0743584632873535\n",
      "Epoch: 464, reconstruction error: 1.0746585130691528\n",
      "Epoch: 465, reconstruction error: 1.0741984844207764\n",
      "Epoch: 466, reconstruction error: 1.0740954875946045\n",
      "Epoch: 467, reconstruction error: 1.07460355758667\n",
      "Epoch: 468, reconstruction error: 1.0740125179290771\n",
      "Epoch: 469, reconstruction error: 1.0745484828948975\n",
      "Epoch: 470, reconstruction error: 1.0741695165634155\n",
      "Epoch: 471, reconstruction error: 1.0744065046310425\n",
      "Epoch: 472, reconstruction error: 1.073920488357544\n",
      "Epoch: 473, reconstruction error: 1.073764443397522\n",
      "Epoch: 474, reconstruction error: 1.074188470840454\n",
      "Epoch: 475, reconstruction error: 1.0739214420318604\n",
      "Epoch: 476, reconstruction error: 1.0739774703979492\n",
      "Epoch: 477, reconstruction error: 1.074094533920288\n",
      "Epoch: 478, reconstruction error: 1.074171543121338\n",
      "Epoch: 479, reconstruction error: 1.0739084482192993\n",
      "Epoch: 480, reconstruction error: 1.0740175247192383\n",
      "Epoch: 481, reconstruction error: 1.0738974809646606\n",
      "Epoch: 482, reconstruction error: 1.0738965272903442\n",
      "Epoch: 483, reconstruction error: 1.074062466621399\n",
      "Epoch: 484, reconstruction error: 1.0738635063171387\n",
      "Epoch: 485, reconstruction error: 1.0740184783935547\n",
      "Epoch: 486, reconstruction error: 1.0739754438400269\n",
      "Epoch: 487, reconstruction error: 1.0739405155181885\n",
      "Epoch: 488, reconstruction error: 1.0739065408706665\n",
      "Epoch: 489, reconstruction error: 1.0737204551696777\n",
      "Epoch: 490, reconstruction error: 1.0739045143127441\n",
      "Epoch: 491, reconstruction error: 1.073488473892212\n",
      "Epoch: 492, reconstruction error: 1.0740225315093994\n",
      "Epoch: 493, reconstruction error: 1.0736345052719116\n",
      "Epoch: 494, reconstruction error: 1.0743515491485596\n",
      "Epoch: 495, reconstruction error: 1.0738584995269775\n",
      "Epoch: 496, reconstruction error: 1.074049472808838\n",
      "Epoch: 497, reconstruction error: 1.0735255479812622\n",
      "Epoch: 498, reconstruction error: 1.074305534362793\n",
      "Epoch: 499, reconstruction error: 1.0735244750976562\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "# Convert input_X into ratings\n",
    "inputX = ratings_train\n",
    "inputX = inputX.astype(np.float32)\n",
    "\n",
    "# Define the parameters of the RBMs we will train\n",
    "rbm = RBM(1000, 1000, 0.3, 500, 200)\n",
    "\n",
    "# Begin training\n",
    "err = rbm.train(inputX)\n",
    "outputX, reconstructedX, hiddenX = rbm.rbm_output(inputX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
