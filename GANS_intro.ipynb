{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adverarial Networks\n",
    "In GANs, we have two neural networks. One network is known as the **generator** which generates data based on a model it has created using samples of real data it has received as input. \n",
    "\n",
    "The other network is known as the **discriminator** which discriminates between the data created by the generator and data from the true distribution. \n",
    "\n",
    "The generator can be seen as the *counterfeiter*, and the discriminator is the *police* trying to identify the forgery. \n",
    "\n",
    "The two networks are locked in a **zero-sum game**. \n",
    "\n",
    "The generator is trying to fool the discriminator into thinking the synthetic data comes from the true distribution, and the discriminator is trying to call out the synthetic data as fake. \n",
    "\n",
    "GANs are unsuperbised learning algorithms because the generator can learn the underlying structure of the true distribution even when there are no labels. \n",
    "\n",
    "The generator learns the underlying structure by using a number of parameters significantly smaller than the amount of data it has trained on.\n",
    "\n",
    "The **constraint** forces the generator to efficiently capture the most salient aspects of the true data distribution. \n",
    "\n",
    "Each hidden layer in the neutral network of a generator captures a representation of the underlying data - starting very simply - and subsequent layers pick up more complicated representations by building on the simpler preceding layers. \n",
    "\n",
    "*Using all these layers together, the generator learns the underlying structure of the data and attempts to create synthetic data that is nearly identical to the true data. If the generator has captures the essence of the true data, the synthetic data will appear real.* \n",
    "\n",
    "GANs can also excel at anomaly detection. If the objective is to identify anomalies - for example: detect fraud, hacking, or other suspiscious behavior - we can use the discriminator to score each instance in the real data. \n",
    "\n",
    "## Deep Convolutional GANs\n",
    "The version of GANs we will use is called *deep convolutional generative adversarial networks (DCGANs)*\n",
    "\n",
    "### Convolutional Neural Networks\n",
    "We will first begin with CNNs to learn more about them before moving onto DCGANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, re, pickle, gzip, datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_recall_curve, average_precision_score, roc_auc_score, auc, roc_curve, mean_squared_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, Conv2D, MaxPool2D, LeakyReLU, Reshape, UpSampling2D, Conv2DTranspose, BatchNormalization, Input, Lambda, Embedding, Flatten, dot\n",
    "from keras import regularizers\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "file = './datasets/mnist_data/mnist.pkl.gz'\n",
    "\n",
    "f = gzip.open(file, 'rb')\n",
    "train_set, validation_set, test_set = pickle.load(f, encoding='latin1')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting our raw data\n",
    "X_train, y_train = train_set[0], train_set[1]\n",
    "X_validation, y_validation = validation_set[0], validation_set[1]\n",
    "X_test, y_test = test_set[0], test_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_keras = X_train.reshape(50000, 28, 28, 1)\n",
    "X_validation_keras = X_validation.reshape(10000, 28, 28, 1)\n",
    "X_test_keras = X_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_keras = to_categorical(y_train)\n",
    "y_validation_keras = to_categorical(y_validation)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PD DF\n",
    "train_index = range(0, len(X_train))\n",
    "validation_index = range(len(X_train), len(X_train) + len(X_validation))\n",
    "test_index = range(len(X_train) + len(X_validation), len(X_train) + len(X_validation) + len(X_test))\n",
    "\n",
    "X_train = pd.DataFrame(data=X_train, index=train_index)\n",
    "y_train = pd.Series(data=y_train, index=train_index)\n",
    "\n",
    "X_validation = pd.DataFrame(data=X_validation, index=validation_index)\n",
    "y_validation = pd.Series(data=y_validation, index=validation_index)\n",
    "\n",
    "X_test = pd.DataFrame(data=X_test, index=test_index)\n",
    "y_test = pd.DataFrame(data=y_test, index=test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show images\n",
    "def view_digit(X, y, example):\n",
    "    label = y.loc[example]\n",
    "    image = X.loc[example, :].values.reshape([28,28])\n",
    "    plt.title(f'Example: {example} Label: {label}')\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAERxJREFUeJzt3X2wHXV9x/H3JwGk8qCJ1EyAQCyNWlQITkzSDLVBkAk4DDDThGCrodBehkKRkYIUxyGdYgfQCHZssXGgBOUpJVAobVWMRWCAlEAhPAQEMmFICIkYGIKlKMm3f+zv6nI4T/fcc86e3N/nNbNzd/e3e/Z7N/ncfT6riMDM8jOu6gLMrBoOv1mmHH6zTDn8Zply+M0y5fCbZcrh30lJOkXSvVXX0Q+SpkoKSbv0c96xzuGvQ9J6SW9Ier3UfavqunpF0tclPSNpm6SnJH2+pn26pIck/W/6Ob3UJkmXSvp56i6VpAbLmStpQ69/n9GQdJak1ZLelHRN1fX0ksPf2HERsWepO6vqgnroF8BxwHuARcA3Jc0BkLQbcBvwPWACsAy4LY0HGAJOAA4FDkmfc3pfq++uF4GLgaurLqTXHP4RknSlpBWl4UslrUxbwAmS7pD0M0mvpP79S9PeJeliSfelvYl/k/Q+SddJek3Sg5KmlqYPSWdLWifpZUlfk1T330zShyXdKWmrpKclLWj3d4qIiyLiqYjYERGrgHuA30/Nc4FdgCsi4s2I+HtAwKdS+yJgSURsiIiNwBLglHaXXar/M5L+J62HFyQtrjPZqZJelLRJ0l+V5h0n6QJJz6W9j+WSJo60BoCIuCUi/hX4eSfz70wc/pE7F/hYOub+A+A0YFEU90mPA/4ZOBA4AHgDqD1cWAh8DtgPOAi4P80zEVgLXFQz/YnADODjwPHAqbUFSdoDuBO4Hnh/WsY/Sjo4tX9W0pp2fjlJvwV8AngijfoIsCbefh/4mjR+uP3RUtujpbaR+AXweeC9wGeAMySdUDPNEcA04GjgS5KOSuP/kmLv4w+BfYFXgH+ot5D0R+KODuobeyLCXU0HrAdeB14tdX9eap8FbAWeB05u8jnTgVdKw3cBXy4NLwH+szR8HPBIaTiAeaXhvwBWpv5TgHtT/0nAPTXL/ifgog5+92XA9wGl4a8AN9ZMcx2wOPVvBz5capuW6ladz54LbGizjiuAy1P/1PSZ5eVcBlyV+tcCR5baJgO/othjGZ53lxGuh4uBa6r+v9jLzmdAGzshIn5UryEiVklaR7GVXT48XtK7gcuBeRTHxwB7SRofEdvT8ObSR71RZ3jPmsW9UOp/nmLLVutAYJakV0vjdgG+W6/+RiR9DfgocESkBFD8Edy7ZtK9gW0N2vcGXi/N3+6yZwGXpOXvBrwL+JeayWrXxcdS/4HArZJ2lNq3A5NGUkNuvNvfAUlnUvznfBE4v9R0LvAhYFZE7A18cniWUSxuSqn/gLTMWi8AP4mI95a6PSPijHYXIulvgGOAoyPitVLTE8AhNWfwD+E3hwVPUJzsG3ZoqW0krgduB6ZExHuAb/PO9dZoXbwAHFPz++8exTkIa8DhHyFJH6TYJfwTimP380uXvvai2Hq/mk441R6/d+K8dCJxCvAF4KY609wBfFDS5yTtmrpPSPq9dhYg6a+BzwJHRUTtia67KLaiZ0t6l6Thqx4/Tj+vBb4oaT9J+1L8AbymxfJ2r+lEse62RsT/SZqZ6qn1FUnvlvQR4E/5zbr4NvBVSQemz/9tSce387vXqW0XSbsD44Hxqb6xuYdc9XHHIHYUx/xvUOzSDne3UuxK/zdwQWnaM4DHKPYE9qUIy+vATykuef36eDO1/Vlp3rcdVwJHAc+WhgM4G1hHcfZ5CTA+tZ1COuZPwx8C/h34WZr2x8D01PbHwBNNft8A3qz5fS8stR8GPJTWycPAYaU2URx/b03dZdQ53k/Tzk3Lqu1+F/gjil35bRR/zL4FfC/NNzVNN0SxtX8JOL/0ueOALwJPp/mfA/6uZt7hf4MLKZ1nqVPj4jr1La76/2QvuuGTOjaAJAUwLSKerboWG3u822+WKYffLFPe7TfLlLf8Zpnq6yWMdALLzHooItq6r2RUW35J89JDJM9KumA0n2Vm/dXxMb+k8RTXsj8NbAAepLjP/ckm83jLb9Zj/djyz6S4IWVdRPwSuJHiqTMz2wmMJvz78fYHLTakcW8jaSh9M8rqUSzLzLqs5yf8ImIpsBS82282SEaz5d/I25+y2j+NM7OdwGjC/yAwTdIH0ve5LaR4JNPMdgId7/ZHxFvp8c4fUDz+eHVEdPIct5lVoK+39/qY36z3+nKTj5ntvBx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2Wqr6/ott6YMmVKw7Ybb7yx6bxz5sxp2j5//vym7TfffHPTdhtc3vKbZcrhN8uUw2+WKYffLFMOv1mmHH6zTDn8Zpnydf4xYPbs2Q3bZs6c2XTeHTt2NG3v51ucrb9GFX5J64FtwHbgrYiY0Y2izKz3urHlPyIiXu7C55hZH/mY3yxTow1/AD+U9JCkoXoTSBqStFrS6lEuy8y6aLS7/YdHxEZJ7wfulPRURNxdniAilgJLAST57JHZgBjVlj8iNqafW4Bbgeanls1sYHQcfkl7SNpruB84Gni8W4WZWW+NZrd/EnCrpOHPuT4ivt+VqmxE0r9BXePGNf/73mxegOXLlzdtHz9+fNN2G1wdhz8i1gGHdrEWM+sjX+ozy5TDb5Yph98sUw6/WaYcfrNM+ZHeMaDZY7etHtltdSmw1fy28/KW3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlK/zjwG9fKS31fw33XRT0/aTTjqpabtVx1t+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTvs4/BlT5PL9f4b3z8pbfLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUr/OPAVU+z99qfhtcLbf8kq6WtEXS46VxEyXdKemZ9HNCb8s0s25rZ7f/GmBezbgLgJURMQ1YmYbNbCfSMvwRcTewtWb08cCy1L8MOKHLdZlZj3V6zD8pIjal/peASY0mlDQEDHW4HDPrkVGf8IuIkNTw6Y6IWAosBWg2nZn1V6eX+jZLmgyQfm7pXklm1g+dhv92YFHqXwTc1p1yzKxfWu72S7oBmAvsI2kDcBFwCbBc0mnA88CCXhZpzd13330dtQHMmTOnabuf5x+7WoY/Ik5u0HRkl2sxsz7y7b1mmXL4zTLl8JtlyuE3y5TDb5YpP9I7BmzYsKFh24svvth0Xj/Smy9v+c0y5fCbZcrhN8uUw2+WKYffLFMOv1mmHH6zTPk6/xjX6pHbVu1+pHfs8pbfLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUr/OPca2et/fz/Pnylt8sUw6/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y5Sv849xfp7fGmm55Zd0taQtkh4vjVssaaOkR1J3bG/LNLNua2e3/xpgXp3xl0fE9NT9R3fLMrNeaxn+iLgb2NqHWsysj0Zzwu8sSWvSYcGERhNJGpK0WtLqUSzLzLqs0/BfCRwETAc2AUsaTRgRSyNiRkTM6HBZZtYDHYU/IjZHxPaI2AF8B5jZ3bLMrNc6Cr+kyaXBE4HHG01rZoNJra7TSroBmAvsA2wGLkrD04EA1gOnR8SmlguTfFF4wIz2On6r5/mXLGl4RMh5553XdF7rTES09SULLW/yiYiT64y+asQVmdlA8e29Zply+M0y5fCbZcrhN8uUw2+WqZaX+rq6MF/qGzjbt29v2t7qUmCrr/ZuNv+uu+7adF7rTLuX+rzlN8uUw2+WKYffLFMOv1mmHH6zTDn8Zply+M0y5a/uzlyvX9HdbP7Zs2c3nfeBBx5o2m6j4y2/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5YpP8+fuSqf51+xYkXTeRcuXNi03erz8/xm1pTDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLV8nl+SVOAa4FJFK/kXhoR35Q0EbgJmErxmu4FEfFK70q1Xli1alXT9lmzZjVtH83z/K2Wbb3Vzpb/LeDciDgYmA2cKelg4AJgZURMA1amYTPbSbQMf0RsioiHU/82YC2wH3A8sCxNtgw4oVdFmln3jeiYX9JU4DBgFTApIjalppcoDgvMbCfR9nf4SdoTWAGcExGvlY/1IiIa3bcvaQgYGm2hZtZdbW35Je1KEfzrIuKWNHqzpMmpfTKwpd68EbE0ImZExIxuFGxm3dEy/Co28VcBayPiG6Wm24FFqX8RcFv3yzOzXmn5SK+kw4F7gMeA4eczL6Q47l8OHAA8T3Gpb2uLz/IjvQNm/vz5Tduvv/76pu1+RffgafeR3pbH/BFxL9Dow44cSVFmNjh8h59Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlF/RbU318hXdVi3/y5hlyuE3y5TDb5Yph98sUw6/WaYcfrNMOfxmmfJ1/szdf//9TdsXLFjQtP2cc85p2n7FFVeMuCbrD2/5zTLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNMtfze/q4uzN/bb9Zz7X5vv7f8Zply+M0y5fCbZcrhN8uUw2+WKYffLFMOv1mmWoZf0hRJ/yXpSUlPSPpCGr9Y0kZJj6Tu2N6Xa2bd0vImH0mTgckR8bCkvYCHgBOABcDrEfH1thfmm3zMeq7dm3xafpNPRGwCNqX+bZLWAvuNrjwzq9qIjvklTQUOA1alUWdJWiPpakkTGswzJGm1pNWjqtTMuqrte/sl7Qn8BPhqRNwiaRLwMhDA31IcGpza4jO822/WY+3u9rcVfkm7AncAP4iIb9RpnwrcEREfbfE5Dr9Zj3XtwR4Vr2G9ClhbDn46ETjsRODxkRZpZtVp52z/4cA9wGPAjjT6QuBkYDrFbv964PR0crDZZ3nLb9ZjXd3t7xaH36z3/Dy/mTXl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5Yph98sUw6/WaZafoFnl70MPF8a3ieNG0SDWtug1gWurVPdrO3Adifs6/P871i4tDoiZlRWQBODWtug1gWurVNV1ebdfrNMOfxmmao6/EsrXn4zg1rboNYFrq1TldRW6TG/mVWn6i2/mVXE4TfLVCXhlzRP0tOSnpV0QRU1NCJpvaTH0mvHK32/YHoH4hZJj5fGTZR0p6Rn0s+670isqLaBeG17k9fKV7ruBu11930/5pc0Hvgp8GlgA/AgcHJEPNnXQhqQtB6YERGV3xAi6ZPA68C1w69Ck3QZsDUiLkl/OCdExJcGpLbFjPC17T2qrdFr5U+hwnXXzdfdd0MVW/6ZwLMRsS4ifgncCBxfQR0DLyLuBrbWjD4eWJb6l1H85+m7BrUNhIjYFBEPp/5twPBr5Stdd03qqkQV4d8PeKE0vIEKV0AdAfxQ0kOShqoupo5JpdeivQRMqrKYOlq+tr2fal4rPzDrrpPX3XebT/i90+ER8XHgGODMtHs7kKI4Zhuka7VXAgdRvMNxE7CkymLSa+VXAOdExGvltirXXZ26KllvVYR/IzClNLx/GjcQImJj+rkFuJXiMGWQbB5+Q3L6uaXien4tIjZHxPaI2AF8hwrXXXqt/Arguoi4JY2ufN3Vq6uq9VZF+B8Epkn6gKTdgIXA7RXU8Q6S9kgnYpC0B3A0g/fq8duBRal/EXBbhbW8zaC8tr3Ra+WpeN0N3OvuI6LvHXAsxRn/54AvV1FDg7p+B3g0dU9UXRtwA8Vu4K8ozo2cBrwPWAk8A/wImDhAtX2X4lXuayiCNrmi2g6n2KVfAzySumOrXndN6qpkvfn2XrNM+YSfWaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5ap/wfER6bemHy1TwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_digit(X_train, y_train, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture \n",
    "model = Sequential()\n",
    "\n",
    "# Layers: 1, 2\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu'))\n",
    "\n",
    "# Pooling layer: 3\n",
    "model.add(MaxPool2D(pool_size=(2,2))) # pooling layer\n",
    "model.add(Dropout(0.25)) # dropout\n",
    "\n",
    "# Layers: 4, 5\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'))\n",
    "\n",
    "# Pooling layer: 6\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25)) # dropout\n",
    "\n",
    "# Flatten images\n",
    "model.add(Flatten())\n",
    "\n",
    "# Layers: 6, 7 (with dropout in between)\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax')) # makes prediction | last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Compiling: Optimizer, Loss, Metrics\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 285s 6ms/step - loss: 0.0615 - acc: 0.9818 - val_loss: 0.0342 - val_acc: 0.9898\n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 321s 6ms/step - loss: 0.0472 - acc: 0.9860 - val_loss: 0.0346 - val_acc: 0.9903\n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 332s 7ms/step - loss: 0.0420 - acc: 0.9865 - val_loss: 0.0286 - val_acc: 0.9923\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "history = model.fit(X_train_keras, y_train_keras, validation_data=(X_validation_keras, y_validation_keras), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.646%\n"
     ]
    }
   ],
   "source": [
    "# Final accuracy\n",
    "print(f\"{history.history['acc'][-1] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGANs Revisited\n",
    "We will build a generative model to product synthetic MNIST images that are very similar to the original MNIST ones. \n",
    "\n",
    "To produce near-realistic yet synthetic images, we need to train a generator that generates new images from the original MNIST images and a discriminator that judges whether those images are believably similar to the original ones or not. \n",
    "\n",
    "The original MNIST dataset represents the original data distribution. The generator learns from this original distribution and generates new images based off what it has learned, and the discrimintor attempts to determine whether the newly generated images are virtually indistinguable from the original distribution or not. \n",
    "\n",
    "The basic architecture of the **DCGAN Generator** is as follows:\n",
    "The generator takes in an initial *noise vector* (100 x 1), and then projects and reshapes it into a (1024 x 4 x 4) tensor. \n",
    "\n",
    "This *project and reshape* action is the opposite of convolution and is known as *transposed convolution or deconvolution*. In transposed convolution, the original process of convolution is reversed, mapping a reduced tensor into a larger one. \n",
    "\n",
    "Here are the various stages:\n",
    "```(100, 1) --> (1024, 4, 4) --> (512, 8, 8) --> (256, 16, 16) --> (128, 32, 32) --> (64, 64, 3)```\n",
    "\n",
    "We will create a class ```DCGAN``` which we will use to build the generator, discriminator, discriminator model, and adversarial model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCGAN Class\n",
    "class DCGAN(object):\n",
    "    def __init__(self, img_rows=28, img_cols=28, channel=1):\n",
    "        \"\"\"\n",
    "        MNIST: (28,28,1) images. That is they are 28 x 28 with only one color\n",
    "        \"\"\"\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channel = channel\n",
    "        self.D = None  # Discriminator\n",
    "        self.G = None  # Generator\n",
    "        self.AM = None # Adversarial Model\n",
    "        self.DM = None # Discriminator Model\n",
    "        \n",
    "    def generator(self, depth=256, dim=7, dropout=0.3, momentum=0.8, window=5, input_dim=100, output_depth=1):\n",
    "        \"\"\"\n",
    "        We are initiliazing our generator based on DCGANs defaults.\n",
    "        (100,1) -> (7,7,256) -> (14,14,128) -> (28,28,64) -> (28,28,32) -> (28,28,1)\n",
    "        \"\"\"\n",
    "        if self.G:\n",
    "            return self.G\n",
    "        \n",
    "        # Initializing\n",
    "        self.G = Sequential()\n",
    "        \n",
    "        # Layer 1 \n",
    "        self.G.add(Dense(dim*dim*depth, input_dim=input_dim))\n",
    "        self.G.add(BatchNormalization(momentum=momentum))\n",
    "        self.G.add(Activation('relu'))\n",
    "        self.G.add(Reshape((dim, dim, depth))) # tensor\n",
    "        self.G.add(Dropout(dropout))\n",
    "        \n",
    "        # Upsampling and transposed convolution - 3 times\n",
    "        self.G.add(UpSampling2D())\n",
    "        self.G.add(Conv2DTranspose(int(depth/2), window, padding=\"same\"))\n",
    "        self.G.add(BatchNormalization(momentum=momentum))\n",
    "        self.G.add(Activation('relu'))\n",
    "        \n",
    "        self.G.add(UpSampling2D())\n",
    "        self.G.add(Conv2DTranspose(int(depth/4), window, padding=\"same\"))\n",
    "        self.G.add(BatchNormalization(momentum=momentum))\n",
    "        self.G.add(Activation('relu'))\n",
    "        \n",
    "        self.G.add(Conv2DTranspose(int(depth/8), window, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=momentum))\n",
    "        self.G.add(Activation('relu'))\n",
    "        \n",
    "        # Final Layer to output\n",
    "        self.G.add(Conv2DTranspose(output_depth, window, padding='same'))\n",
    "        self.G.add(Activation('sigmoid'))\n",
    "        self.G.summary()\n",
    "        \n",
    "        return self.G\n",
    "    \n",
    "    def discriminator(self, depth=64, dropout=0.3, alpha=0.3):\n",
    "        if self.D:\n",
    "            return self.D\n",
    "        \n",
    "        # instantiating the discrimnator model\n",
    "        self.D = Sequential()\n",
    "        \n",
    "        # Initializing our input shape\n",
    "        input_shape = (self.img_rows, self.img_cols, self.channel)\n",
    "        \n",
    "        # LAYERS\n",
    "        self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=alpha))\n",
    "        self.D.add(Dropout(dropout))\n",
    "        \n",
    "        self.D.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=alpha))\n",
    "        self.D.add(Dropout(dropout))\n",
    "        \n",
    "        self.D.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=alpha))\n",
    "        self.D.add(Dropout(dropout))\n",
    "        \n",
    "        self.D.add(Conv2D(depth*8, 5, strides=1, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=alpha))\n",
    "        self.D.add(Dropout(dropout))\n",
    "        \n",
    "        # Final dense layer \n",
    "        self.D.add(Flatten())\n",
    "        self.D.add(Dense(1))\n",
    "        self.D.add(Activation('sigmoid'))\n",
    "        self.D.summary()\n",
    "        \n",
    "        return self.D\n",
    "    \n",
    "    \n",
    "    def discriminator_model(self):\n",
    "        \"\"\"\n",
    "        The police detecting the fake\n",
    "        \"\"\"\n",
    "        if self.DM:\n",
    "            return self.DM\n",
    "        \n",
    "        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "        self.DM = Sequential()\n",
    "        self.DM.add(self.discriminator()) # calling D\n",
    "        self.DM.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return self.DM\n",
    "    \n",
    "    def adversarial_model(self):\n",
    "        \"\"\"\n",
    "        The counterfeiter\n",
    "        \"\"\"\n",
    "        if self.AM:\n",
    "            return self.AM\n",
    "        \n",
    "        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "        self.AM = Sequential()\n",
    "        self.AM.add(self.generator())\n",
    "        self.AM.add(self.discriminator())\n",
    "        self.AM.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return self.AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCGAN for MNIST\n",
    "class MNIST_DCGAN(object):\n",
    "    def __init__(self, x_train):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channel = 1\n",
    "        self.x_train = x_train # input data\n",
    "        \n",
    "        # instantiating models\n",
    "        self.DCGAN = DCGAN()\n",
    "        self.discriminator = self.DCGAN.discriminator_model()\n",
    "        self.adversarial = self.DCGAN.adversarial_model()\n",
    "        self.generator = self.DCGAN.generator()\n",
    "        \n",
    "    # Training method\n",
    "    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n",
    "        noise_input = None\n",
    "        \n",
    "        if save_interval > 0:\n",
    "            noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "            \n",
    "        for i in range(train_steps):\n",
    "            images_train = self.x_train[np.random.randint(0, self.x_train.shape[0], size=batch_size), :, :, :]\n",
    "            \n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            \n",
    "            images_fake = self.generator.predict(noise)\n",
    "            \n",
    "            x = np.concatenate([images_train, images_fake])\n",
    "            y = np.ones([2 * batch_size, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "            \n",
    "            d_loss = self.discriminator.train_on_batch(x, y)\n",
    "            \n",
    "            y = np.ones([batch_size, 1])\n",
    "            \n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            \n",
    "            a_loss = self.adversarial.train_on_batch(noise, y)\n",
    "            \n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], \\\n",
    "                                                      a_loss[1])\n",
    "            \n",
    "            print(log_mesg)\n",
    "            if save_interval > 0:\n",
    "                if (i + 1)%save_interval == 0:\n",
    "                    self.plot_images(save2file=True, samples=noise_input.shape[0], noise=noise_input, steps=(i+1))\n",
    "                    \n",
    "    # Plotting method\n",
    "    def plot_images(self, save2file=False, fake=True, samples=16, \\\n",
    "                noise=None, step=0):\n",
    "        current_path = os.getcwd()\n",
    "        file = '/images/chapter12/synthetic_mnist/'\n",
    "        filename = 'mnist.png'\n",
    "        if fake:\n",
    "            if noise is None:\n",
    "                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n",
    "            else:\n",
    "                filename = \"mnist_%d.png\" % step\n",
    "            images = self.generator.predict(noise)\n",
    "        else:\n",
    "            i = np.random.randint(0, self.x_train.shape[0], samples)\n",
    "            images = self.x_train[i, :, :, :]\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            image = images[i, :, :, :]\n",
    "            image = np.reshape(image, [self.img_rows, self.img_cols])\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        if save2file:\n",
    "            plt.savefig(current_path+file+filename)\n",
    "            plt.close('all')\n",
    "        else:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "    def elapsed(self,sec):\n",
    "        if sec < 60:\n",
    "            return str(sec) + \" sec\"\n",
    "        elif sec < (60 * 60):\n",
    "            return str(sec / 60) + \" min\"\n",
    "        else:\n",
    "            return str(sec / (60 * 60)) + \" hr\"\n",
    "    def elapsed_time(self):\n",
    "        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 8193      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,311,553\n",
      "Trainable params: 4,311,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 12544)             1266944   \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DT (None, 14, 14, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_18 (Conv2DT (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_19 (Conv2DT (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_20 (Conv2DT (None, 28, 28, 1)         801       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 2,394,241\n",
      "Trainable params: 2,368,705\n",
      "Non-trainable params: 25,536\n",
      "_________________________________________________________________\n",
      "0: [D loss: 0.692277, acc: 0.521484]  [A loss: 1.820358, acc: 0.000000]\n",
      "1: [D loss: 0.636805, acc: 0.986328]  [A loss: 2.921914, acc: 0.000000]\n",
      "2: [D loss: 0.587545, acc: 0.929688]  [A loss: 0.564671, acc: 0.992188]\n",
      "3: [D loss: 1.693680, acc: 0.500000]  [A loss: 5.374488, acc: 0.000000]\n",
      "4: [D loss: 0.362553, acc: 0.960938]  [A loss: 2.229707, acc: 0.000000]\n",
      "5: [D loss: 0.627849, acc: 0.564453]  [A loss: 11.493404, acc: 0.000000]\n",
      "6: [D loss: 0.627697, acc: 0.585938]  [A loss: 0.327361, acc: 0.988281]\n",
      "7: [D loss: 1.744360, acc: 0.498047]  [A loss: 9.197357, acc: 0.000000]\n",
      "8: [D loss: 0.712865, acc: 0.609375]  [A loss: 0.562309, acc: 0.781250]\n",
      "9: [D loss: 1.599079, acc: 0.498047]  [A loss: 7.563826, acc: 0.000000]\n",
      "10: [D loss: 0.620857, acc: 0.693359]  [A loss: 0.684873, acc: 0.566406]\n",
      "11: [D loss: 1.525923, acc: 0.492188]  [A loss: 8.184240, acc: 0.000000]\n",
      "12: [D loss: 0.684508, acc: 0.652344]  [A loss: 0.483513, acc: 0.867188]\n",
      "13: [D loss: 1.602962, acc: 0.488281]  [A loss: 7.113887, acc: 0.000000]\n",
      "14: [D loss: 0.646850, acc: 0.707031]  [A loss: 0.687240, acc: 0.554688]\n",
      "15: [D loss: 1.591942, acc: 0.494141]  [A loss: 8.131655, acc: 0.000000]\n",
      "16: [D loss: 0.839898, acc: 0.607422]  [A loss: 0.296481, acc: 0.992188]\n",
      "17: [D loss: 1.559332, acc: 0.496094]  [A loss: 6.261192, acc: 0.000000]\n",
      "18: [D loss: 0.643829, acc: 0.708984]  [A loss: 0.916979, acc: 0.261719]\n",
      "19: [D loss: 1.576838, acc: 0.492188]  [A loss: 8.526599, acc: 0.000000]\n",
      "20: [D loss: 0.863309, acc: 0.568359]  [A loss: 0.175196, acc: 1.000000]\n",
      "21: [D loss: 1.539883, acc: 0.492188]  [A loss: 5.233859, acc: 0.000000]\n",
      "22: [D loss: 0.634705, acc: 0.718750]  [A loss: 1.091423, acc: 0.089844]\n",
      "23: [D loss: 1.427550, acc: 0.494141]  [A loss: 8.657335, acc: 0.000000]\n",
      "24: [D loss: 0.912439, acc: 0.521484]  [A loss: 0.078871, acc: 1.000000]\n",
      "25: [D loss: 1.727475, acc: 0.500000]  [A loss: 4.872100, acc: 0.000000]\n",
      "26: [D loss: 0.591128, acc: 0.732422]  [A loss: 1.270088, acc: 0.042969]\n",
      "27: [D loss: 1.333262, acc: 0.498047]  [A loss: 8.860213, acc: 0.000000]\n",
      "28: [D loss: 0.966497, acc: 0.529297]  [A loss: 0.060354, acc: 1.000000]\n",
      "29: [D loss: 1.758183, acc: 0.500000]  [A loss: 4.653211, acc: 0.000000]\n",
      "30: [D loss: 0.600310, acc: 0.710938]  [A loss: 1.291465, acc: 0.066406]\n",
      "31: [D loss: 1.300136, acc: 0.500000]  [A loss: 8.164394, acc: 0.000000]\n",
      "32: [D loss: 0.860579, acc: 0.552734]  [A loss: 0.043657, acc: 1.000000]\n",
      "33: [D loss: 1.869108, acc: 0.500000]  [A loss: 5.152279, acc: 0.000000]\n",
      "34: [D loss: 0.581289, acc: 0.751953]  [A loss: 0.838831, acc: 0.359375]\n",
      "35: [D loss: 1.329198, acc: 0.494141]  [A loss: 8.139649, acc: 0.000000]\n",
      "36: [D loss: 0.788486, acc: 0.558594]  [A loss: 0.056468, acc: 1.000000]\n",
      "37: [D loss: 1.784233, acc: 0.500000]  [A loss: 5.070882, acc: 0.000000]\n",
      "38: [D loss: 0.557044, acc: 0.769531]  [A loss: 0.684590, acc: 0.539062]\n",
      "39: [D loss: 1.404477, acc: 0.500000]  [A loss: 8.495901, acc: 0.000000]\n",
      "40: [D loss: 0.856434, acc: 0.527344]  [A loss: 0.030750, acc: 1.000000]\n",
      "41: [D loss: 2.047945, acc: 0.500000]  [A loss: 4.032081, acc: 0.000000]\n",
      "42: [D loss: 0.553577, acc: 0.701172]  [A loss: 2.410950, acc: 0.000000]\n",
      "43: [D loss: 1.062388, acc: 0.501953]  [A loss: 8.535981, acc: 0.000000]\n",
      "44: [D loss: 0.907956, acc: 0.527344]  [A loss: 0.011613, acc: 1.000000]\n",
      "45: [D loss: 2.413108, acc: 0.500000]  [A loss: 3.191546, acc: 0.000000]\n",
      "46: [D loss: 0.741192, acc: 0.544922]  [A loss: 4.566460, acc: 0.000000]\n",
      "47: [D loss: 0.643775, acc: 0.621094]  [A loss: 3.215605, acc: 0.000000]\n",
      "48: [D loss: 0.926560, acc: 0.517578]  [A loss: 8.364480, acc: 0.000000]\n",
      "49: [D loss: 0.828217, acc: 0.550781]  [A loss: 0.006233, acc: 1.000000]\n",
      "50: [D loss: 2.799586, acc: 0.500000]  [A loss: 4.031547, acc: 0.000000]\n",
      "51: [D loss: 0.602826, acc: 0.632812]  [A loss: 2.708082, acc: 0.000000]\n",
      "52: [D loss: 0.941782, acc: 0.509766]  [A loss: 8.406618, acc: 0.000000]\n",
      "53: [D loss: 0.988858, acc: 0.519531]  [A loss: 0.004332, acc: 1.000000]\n",
      "54: [D loss: 2.849928, acc: 0.500000]  [A loss: 1.739589, acc: 0.007812]\n",
      "55: [D loss: 0.947905, acc: 0.509766]  [A loss: 6.119858, acc: 0.000000]\n",
      "56: [D loss: 0.642046, acc: 0.638672]  [A loss: 0.054465, acc: 1.000000]\n",
      "57: [D loss: 1.731386, acc: 0.500000]  [A loss: 4.200591, acc: 0.000000]\n",
      "58: [D loss: 0.533021, acc: 0.732422]  [A loss: 1.010137, acc: 0.242188]\n",
      "59: [D loss: 1.223545, acc: 0.501953]  [A loss: 8.334019, acc: 0.000000]\n",
      "60: [D loss: 1.018731, acc: 0.523438]  [A loss: 0.004469, acc: 1.000000]\n",
      "61: [D loss: 2.943115, acc: 0.500000]  [A loss: 0.966406, acc: 0.238281]\n",
      "62: [D loss: 1.016196, acc: 0.501953]  [A loss: 4.780180, acc: 0.000000]\n",
      "63: [D loss: 0.568038, acc: 0.701172]  [A loss: 0.490828, acc: 0.816406]\n",
      "64: [D loss: 1.314092, acc: 0.501953]  [A loss: 7.226668, acc: 0.000000]\n",
      "65: [D loss: 0.776219, acc: 0.597656]  [A loss: 0.008444, acc: 1.000000]\n",
      "66: [D loss: 2.499308, acc: 0.500000]  [A loss: 1.908291, acc: 0.007812]\n",
      "67: [D loss: 0.993683, acc: 0.503906]  [A loss: 5.946885, acc: 0.000000]\n",
      "68: [D loss: 0.620671, acc: 0.662109]  [A loss: 0.235803, acc: 0.988281]\n",
      "69: [D loss: 1.327147, acc: 0.500000]  [A loss: 6.153750, acc: 0.000000]\n",
      "70: [D loss: 0.630053, acc: 0.683594]  [A loss: 0.044787, acc: 1.000000]\n",
      "71: [D loss: 1.830098, acc: 0.500000]  [A loss: 3.947884, acc: 0.000000]\n",
      "72: [D loss: 0.613345, acc: 0.605469]  [A loss: 2.440236, acc: 0.000000]\n",
      "73: [D loss: 1.330728, acc: 0.500000]  [A loss: 10.995110, acc: 0.000000]\n",
      "74: [D loss: 1.460761, acc: 0.505859]  [A loss: 0.000344, acc: 1.000000]\n",
      "75: [D loss: 4.218536, acc: 0.500000]  [A loss: 0.216314, acc: 0.980469]\n",
      "76: [D loss: 1.290758, acc: 0.500000]  [A loss: 3.841751, acc: 0.000000]\n",
      "77: [D loss: 0.614016, acc: 0.605469]  [A loss: 1.712466, acc: 0.031250]\n",
      "78: [D loss: 1.241038, acc: 0.503906]  [A loss: 7.192927, acc: 0.000000]\n",
      "79: [D loss: 0.680100, acc: 0.671875]  [A loss: 0.023891, acc: 1.000000]\n",
      "80: [D loss: 2.001626, acc: 0.500000]  [A loss: 3.770144, acc: 0.000000]\n",
      "81: [D loss: 0.675762, acc: 0.574219]  [A loss: 3.064730, acc: 0.000000]\n",
      "82: [D loss: 0.973526, acc: 0.505859]  [A loss: 7.348772, acc: 0.000000]\n",
      "83: [D loss: 0.706170, acc: 0.671875]  [A loss: 0.009336, acc: 1.000000]\n",
      "84: [D loss: 2.386305, acc: 0.500000]  [A loss: 3.470718, acc: 0.000000]\n",
      "85: [D loss: 0.785561, acc: 0.529297]  [A loss: 4.595192, acc: 0.000000]\n",
      "86: [D loss: 0.734384, acc: 0.560547]  [A loss: 5.114698, acc: 0.000000]\n",
      "87: [D loss: 0.666975, acc: 0.562500]  [A loss: 3.857978, acc: 0.000000]\n",
      "88: [D loss: 1.095355, acc: 0.513672]  [A loss: 11.799137, acc: 0.000000]\n",
      "89: [D loss: 1.980160, acc: 0.503906]  [A loss: 0.000015, acc: 1.000000]\n",
      "90: [D loss: 5.703953, acc: 0.500000]  [A loss: 0.046884, acc: 1.000000]\n",
      "91: [D loss: 1.748035, acc: 0.500000]  [A loss: 3.322800, acc: 0.000000]\n",
      "92: [D loss: 0.696725, acc: 0.548828]  [A loss: 3.257323, acc: 0.000000]\n",
      "93: [D loss: 0.899418, acc: 0.511719]  [A loss: 5.854941, acc: 0.000000]\n",
      "94: [D loss: 0.637158, acc: 0.642578]  [A loss: 0.533037, acc: 0.738281]\n",
      "95: [D loss: 1.401172, acc: 0.500000]  [A loss: 9.333492, acc: 0.000000]\n",
      "96: [D loss: 1.324937, acc: 0.535156]  [A loss: 0.000100, acc: 1.000000]\n",
      "97: [D loss: 4.698832, acc: 0.500000]  [A loss: 0.110660, acc: 1.000000]\n",
      "98: [D loss: 1.453860, acc: 0.500000]  [A loss: 3.890142, acc: 0.000000]\n",
      "99: [D loss: 0.658195, acc: 0.576172]  [A loss: 2.039603, acc: 0.011719]\n",
      "100: [D loss: 1.303514, acc: 0.503906]  [A loss: 8.623734, acc: 0.000000]\n",
      "101: [D loss: 0.969009, acc: 0.625000]  [A loss: 0.000898, acc: 1.000000]\n",
      "102: [D loss: 3.709536, acc: 0.500000]  [A loss: 1.090107, acc: 0.253906]\n",
      "103: [D loss: 1.376247, acc: 0.505859]  [A loss: 7.151733, acc: 0.000000]\n",
      "104: [D loss: 0.737807, acc: 0.646484]  [A loss: 0.031325, acc: 1.000000]\n",
      "105: [D loss: 2.044834, acc: 0.500000]  [A loss: 4.900828, acc: 0.000000]\n",
      "106: [D loss: 0.645570, acc: 0.636719]  [A loss: 1.068687, acc: 0.285156]\n",
      "107: [D loss: 1.568673, acc: 0.498047]  [A loss: 9.656267, acc: 0.000000]\n",
      "108: [D loss: 1.055471, acc: 0.587891]  [A loss: 0.000102, acc: 1.000000]\n",
      "109: [D loss: 4.821718, acc: 0.500000]  [A loss: 0.499272, acc: 0.742188]\n",
      "110: [D loss: 1.421062, acc: 0.501953]  [A loss: 7.233935, acc: 0.000000]\n",
      "111: [D loss: 0.699543, acc: 0.654297]  [A loss: 0.119395, acc: 0.988281]\n",
      "112: [D loss: 1.676124, acc: 0.500000]  [A loss: 6.740499, acc: 0.000000]\n",
      "113: [D loss: 0.719971, acc: 0.664062]  [A loss: 0.009927, acc: 1.000000]\n",
      "114: [D loss: 2.488789, acc: 0.500000]  [A loss: 3.441097, acc: 0.000000]\n",
      "115: [D loss: 0.983917, acc: 0.501953]  [A loss: 6.209129, acc: 0.000000]\n",
      "116: [D loss: 0.662164, acc: 0.619141]  [A loss: 0.617370, acc: 0.656250]\n",
      "117: [D loss: 1.619947, acc: 0.500000]  [A loss: 10.702989, acc: 0.000000]\n",
      "118: [D loss: 1.200506, acc: 0.603516]  [A loss: 0.000087, acc: 1.000000]\n",
      "119: [D loss: 5.091871, acc: 0.500000]  [A loss: 0.157917, acc: 0.992188]\n",
      "120: [D loss: 1.455695, acc: 0.501953]  [A loss: 4.951449, acc: 0.000000]\n",
      "121: [D loss: 0.651165, acc: 0.597656]  [A loss: 2.090579, acc: 0.015625]\n",
      "122: [D loss: 1.782157, acc: 0.500000]  [A loss: 11.234436, acc: 0.000000]\n",
      "123: [D loss: 1.145710, acc: 0.585938]  [A loss: 0.000094, acc: 1.000000]\n",
      "124: [D loss: 4.907491, acc: 0.500000]  [A loss: 0.942262, acc: 0.417969]\n",
      "125: [D loss: 1.777149, acc: 0.500000]  [A loss: 8.606555, acc: 0.000000]\n",
      "126: [D loss: 0.754958, acc: 0.646484]  [A loss: 0.010853, acc: 1.000000]\n",
      "127: [D loss: 2.476645, acc: 0.500000]  [A loss: 5.618459, acc: 0.000000]\n",
      "128: [D loss: 0.713721, acc: 0.601562]  [A loss: 3.479859, acc: 0.000000]\n",
      "129: [D loss: 1.589753, acc: 0.501953]  [A loss: 12.464294, acc: 0.000000]\n",
      "130: [D loss: 1.854121, acc: 0.539062]  [A loss: 0.000002, acc: 1.000000]\n",
      "131: [D loss: 7.137995, acc: 0.500000]  [A loss: 0.003714, acc: 1.000000]\n",
      "132: [D loss: 3.015166, acc: 0.500000]  [A loss: 2.485019, acc: 0.015625]\n",
      "133: [D loss: 1.688968, acc: 0.500000]  [A loss: 8.175036, acc: 0.000000]\n",
      "134: [D loss: 0.724653, acc: 0.591797]  [A loss: 0.442950, acc: 0.808594]\n",
      "135: [D loss: 1.728109, acc: 0.500000]  [A loss: 9.768629, acc: 0.000000]\n",
      "136: [D loss: 0.932103, acc: 0.650391]  [A loss: 0.000871, acc: 1.000000]\n",
      "137: [D loss: 3.882424, acc: 0.500000]  [A loss: 1.830851, acc: 0.054688]\n",
      "138: [D loss: 1.793716, acc: 0.498047]  [A loss: 8.713112, acc: 0.000000]\n",
      "139: [D loss: 0.779224, acc: 0.625000]  [A loss: 0.018750, acc: 1.000000]\n",
      "140: [D loss: 2.369647, acc: 0.500000]  [A loss: 6.621969, acc: 0.000000]\n",
      "141: [D loss: 0.662458, acc: 0.636719]  [A loss: 2.172516, acc: 0.058594]\n",
      "142: [D loss: 2.071292, acc: 0.500000]  [A loss: 12.270899, acc: 0.000000]\n",
      "143: [D loss: 1.441345, acc: 0.591797]  [A loss: 0.000007, acc: 1.000000]\n",
      "144: [D loss: 6.274670, acc: 0.500000]  [A loss: 0.035569, acc: 1.000000]\n",
      "145: [D loss: 2.055228, acc: 0.500000]  [A loss: 5.762555, acc: 0.000000]\n",
      "146: [D loss: 0.765763, acc: 0.593750]  [A loss: 4.995441, acc: 0.000000]\n",
      "147: [D loss: 1.203537, acc: 0.515625]  [A loss: 8.927446, acc: 0.000000]\n",
      "148: [D loss: 0.694270, acc: 0.654297]  [A loss: 0.205564, acc: 0.945312]\n",
      "149: [D loss: 1.680675, acc: 0.498047]  [A loss: 10.391211, acc: 0.000000]\n",
      "150: [D loss: 1.138779, acc: 0.636719]  [A loss: 0.000080, acc: 1.000000]\n",
      "151: [D loss: 5.456249, acc: 0.500000]  [A loss: 0.232112, acc: 0.925781]\n",
      "152: [D loss: 1.615214, acc: 0.501953]  [A loss: 6.654849, acc: 0.000000]\n",
      "153: [D loss: 0.740729, acc: 0.625000]  [A loss: 2.088582, acc: 0.074219]\n",
      "154: [D loss: 2.223465, acc: 0.498047]  [A loss: 13.080106, acc: 0.000000]\n",
      "155: [D loss: 2.041789, acc: 0.556641]  [A loss: 0.000001, acc: 1.000000]\n",
      "156: [D loss: 7.387112, acc: 0.500000]  [A loss: 0.000094, acc: 1.000000]\n",
      "157: [D loss: 5.749222, acc: 0.500000]  [A loss: 0.249114, acc: 0.937500]\n",
      "158: [D loss: 1.722118, acc: 0.507812]  [A loss: 7.702151, acc: 0.000000]\n",
      "159: [D loss: 0.878263, acc: 0.578125]  [A loss: 5.291344, acc: 0.000000]\n",
      "160: [D loss: 1.872157, acc: 0.507812]  [A loss: 12.945764, acc: 0.000000]\n",
      "161: [D loss: 1.299429, acc: 0.617188]  [A loss: 0.000038, acc: 1.000000]\n",
      "162: [D loss: 6.703096, acc: 0.500000]  [A loss: 0.019930, acc: 1.000000]\n",
      "163: [D loss: 2.823164, acc: 0.500000]  [A loss: 6.886497, acc: 0.000000]\n",
      "164: [D loss: 1.200436, acc: 0.544922]  [A loss: 10.021154, acc: 0.000000]\n",
      "165: [D loss: 0.904703, acc: 0.611328]  [A loss: 1.502375, acc: 0.273438]\n",
      "166: [D loss: 3.134022, acc: 0.500000]  [A loss: 15.182837, acc: 0.000000]\n",
      "167: [D loss: 6.874559, acc: 0.500000]  [A loss: 0.004201, acc: 1.000000]\n",
      "168: [D loss: 4.514262, acc: 0.500000]  [A loss: 5.637353, acc: 0.000000]\n",
      "169: [D loss: 2.817856, acc: 0.507812]  [A loss: 14.318774, acc: 0.000000]\n",
      "170: [D loss: 4.742852, acc: 0.500000]  [A loss: 0.000015, acc: 1.000000]\n",
      "171: [D loss: 7.378862, acc: 0.500000]  [A loss: 0.000307, acc: 1.000000]\n",
      "172: [D loss: 6.238754, acc: 0.500000]  [A loss: 0.073506, acc: 0.980469]\n",
      "173: [D loss: 3.031894, acc: 0.501953]  [A loss: 10.598289, acc: 0.000000]\n",
      "174: [D loss: 1.485197, acc: 0.593750]  [A loss: 10.340821, acc: 0.000000]\n",
      "175: [D loss: 1.258472, acc: 0.568359]  [A loss: 7.928678, acc: 0.000000]\n",
      "176: [D loss: 2.587461, acc: 0.515625]  [A loss: 15.233589, acc: 0.000000]\n",
      "177: [D loss: 7.867173, acc: 0.500000]  [A loss: 10.368555, acc: 0.000000]\n",
      "178: [D loss: 1.177499, acc: 0.593750]  [A loss: 5.139484, acc: 0.027344]\n",
      "179: [D loss: 3.631294, acc: 0.505859]  [A loss: 15.623693, acc: 0.000000]\n",
      "180: [D loss: 8.036263, acc: 0.500000]  [A loss: 14.296406, acc: 0.000000]\n",
      "181: [D loss: 7.445260, acc: 0.500000]  [A loss: 0.177854, acc: 0.917969]\n",
      "182: [D loss: 3.141881, acc: 0.517578]  [A loss: 12.619987, acc: 0.000000]\n",
      "183: [D loss: 3.227312, acc: 0.541016]  [A loss: 0.000726, acc: 1.000000]\n",
      "184: [D loss: 6.712976, acc: 0.500000]  [A loss: 0.004536, acc: 1.000000]\n",
      "185: [D loss: 6.290705, acc: 0.500000]  [A loss: 0.028713, acc: 0.992188]\n",
      "186: [D loss: 5.219344, acc: 0.501953]  [A loss: 0.524229, acc: 0.714844]\n",
      "187: [D loss: 3.550573, acc: 0.539062]  [A loss: 12.506318, acc: 0.000000]\n",
      "188: [D loss: 1.813061, acc: 0.599609]  [A loss: 0.006424, acc: 1.000000]\n",
      "189: [D loss: 5.858146, acc: 0.500000]  [A loss: 0.122321, acc: 0.945312]\n",
      "190: [D loss: 3.279596, acc: 0.515625]  [A loss: 9.909113, acc: 0.000000]\n",
      "191: [D loss: 2.238492, acc: 0.576172]  [A loss: 12.975494, acc: 0.000000]\n",
      "192: [D loss: 4.172749, acc: 0.519531]  [A loss: 0.001444, acc: 1.000000]\n",
      "193: [D loss: 6.847310, acc: 0.500000]  [A loss: 0.002819, acc: 1.000000]\n",
      "194: [D loss: 6.036492, acc: 0.500000]  [A loss: 0.024057, acc: 1.000000]\n",
      "195: [D loss: 5.042907, acc: 0.501953]  [A loss: 0.279330, acc: 0.839844]\n",
      "196: [D loss: 3.568637, acc: 0.529297]  [A loss: 8.739417, acc: 0.000000]\n",
      "197: [D loss: 5.190267, acc: 0.509766]  [A loss: 10.672956, acc: 0.000000]\n",
      "198: [D loss: 4.767286, acc: 0.513672]  [A loss: 14.947439, acc: 0.000000]\n",
      "199: [D loss: 7.223621, acc: 0.500000]  [A loss: 0.073528, acc: 0.964844]\n"
     ]
    }
   ],
   "source": [
    "# Initializing MNIST DCGAN and train\n",
    "mnist_dcgan = MNIST_DCGAN(X_train_keras)\n",
    "# time = ElapsedTimer()\n",
    "mnist_dcgan.train(train_steps=200, batch_size=256, save_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MNIST_DCGAN' object has no attribute 'plot_images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-9ebaec21cd7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmnist_dcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MNIST_DCGAN' object has no attribute 'plot_images'"
     ]
    }
   ],
   "source": [
    "mnist_dcgan.plot_images(fake=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
